[
  {
    "question": "Ποιος είναι ο κύριος στόχος της διαχείρισης δεδομένων (Data Management) στο πλαίσιο της Τεχνητής Νοημοσύνης;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 93",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Η οργάνωση, αποθήκευση και επεξεργασία δεδομένων για την υποστήριξη των μοντέλων AI.",
      "B": "Η δημιουργία νέων αλγορίθμων Τεχνητής Νοημοσύνης από το μηδέν.",
      "C": "Η πώληση των δεδομένων σε τρίτες εταιρείες για κερδοσκοπικούς λόγους.",
      "D": "Η αρχειοθέτηση των δεδομένων χωρίς πρόθεση μελλοντικής χρήσης."
    },
    "explanation": "Η διαχείριση δεδομένων στην Τεχνητή Νοημοσύνη εστιάζει στη συστηματική οργάνωση, αποθήκευση και επεξεργασία των δεδομένων, με σκοπό να διασφαλιστεί η ποιότητα, η αξιοπιστία και η διαθεσιμότητά τους για την εκπαίδευση και τη λειτουργία των αλγορίθμων."
  },
  {
    "question": "Ποια από τις παρακάτω ΔΕΝ αποτελεί βασική τεχνική καθαρισμού δεδομένων (Data Cleaning);",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 94-95",
      "paragraph": "3η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Χειρισμός ελλιπών δεδομένων (Handling Missing Data).",
      "B": "Ανίχνευση και διόρθωση σφαλμάτων (Error Detection & Correction).",
      "C": "Ανίχνευση και διαχείριση ακραίων τιμών (Outlier Detection & Handling).",
      "D": "Αυτόματη παραγωγή νέων δεδομένων (Synthetic Data Generation)."
    },
    "explanation": "Οι βασικές τεχνικές καθαρισμού περιλαμβάνουν τον χειρισμό ελλιπών τιμών, τη διόρθωση σφαλμάτων και τη διαχείριση ακραίων τιμών. Η αυτόματη παραγωγή νέων δεδομένων είναι μια διαφορετική τεχνική που χρησιμοποιείται για την αύξηση του όγκου του dataset, όχι για τον καθαρισμό του."
  },
  {
    "question": "Σύμφωνα με το κείμενο, ποια είναι η θεμελιώδης διαφορά μεταξύ δομημένων (structured) και μη δομημένων (unstructured) δεδομένων;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 91",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Τα δομημένα δεδομένα είναι πάντα αριθμητικά, ενώ τα μη δομημένα είναι κειμενικά.",
      "B": "Τα δομημένα έχουν καθορισμένο σχήμα και οργανώνονται εύκολα, ενώ τα μη δομημένα δεν έχουν συγκεκριμένη εσωτερική δομή.",
      "C": "Τα μη δομημένα δεδομένα προέρχονται αποκλειστικά από το διαδίκτυο.",
      "D": "Τα δομημένα δεδομένα δεν χρειάζονται ποτέ καθαρισμό."
    },
    "explanation": "Τα δομημένα δεδομένα, όπως οι βάσεις δεδομένων SQL, έχουν συγκεκριμένη οργάνωση σε πίνακες με στήλες και γραμμές. Αντίθετα, τα μη δομημένα δεδομένα, όπως κείμενα, εικόνες και βίντεο, δεν ακολουθούν ένα προκαθορισμένο μοντέλο, καθιστώντας την ανάλυσή τους πιο πολύπλοκη."
  },
  {
    "question": "Γιατί η ανίχνευση και διαχείριση προκαταλήψεων (Bias Detection & Handling) είναι κρίσιμη κατά την προεπεξεργασία δεδομένων για την AI;",
    "answer": "C",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 95",
      "paragraph": "6η παράγραφος"
    },
    "choices": {
      "A": "Για να αυξηθεί η ταχύτητα επεξεργασίας των αλγορίθμων.",
      "B": "Για να μειωθεί ο όγκος των δεδομένων που απαιτούνται για την εκπαίδευση.",
      "C": "Για την αποφυγή δημιουργίας μοντέλων που οδηγούν σε στρεβλές ή άδικες αποφάσεις.",
      "D": "Για να απλοποιηθεί η διαδικασία κρυπτογράφησης των δεδομένων."
    },
    "explanation": "Οι προκαταλήψεις στα δεδομένα εκπαίδευσης μπορούν να οδηγήσουν ένα μοντέλο Τεχνητής Νοημοσύνης στην αναπαραγωγή και ενίσχυση υπαρχόντων στερεοτύπων, οδηγώντας σε άδικες ή μεροληπτικές αποφάσεις. Η διαχείρισή τους είναι θεμελιώδης για τη δημιουργία δίκαιων και αξιόπιστων συστημάτων."
  },
  {
    "question": "Ποια από τις παρακάτω πηγές δεδομένων ανήκει στην κατηγορία των 'Εσωτερικών Πηγών' (Internal Sources) για έναν οργανισμό;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 92",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Συστήματα CRM (Customer Relationship Management) και ERP (Enterprise Resource Planning).",
      "B": "Δεδομένα από μέσα κοινωνικής δικτύωσης και δημόσια διαθέσιμα σύνολα δεδομένων (public datasets).",
      "C": "Κυβερνητικές βάσεις δεδομένων και ακαδημαϊκές έρευνες.",
      "D": "Δεδομένα από τον παγκόσμιο ιστό μέσω web scraping."
    },
    "explanation": "Οι εσωτερικές πηγές περιλαμβάνουν δεδομένα που παράγονται και συλλέγονται εντός του οργανισμού. Τα συστήματα CRM και ERP είναι κλασικά παραδείγματα τέτοιων πηγών, καθώς περιέχουν πληροφορίες για πελάτες, πωλήσεις και εσωτερικές λειτουργίες."
  },
  {
    "question": "Τι περιλαμβάνει η τεχνική 'Εξαγωγή Χαρακτηριστικών' (Feature Extraction) στον μετασχηματισμό δεδομένων;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 99",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Τη διαγραφή όλων των μη αριθμητικών μεταβλητών από το σύνολο δεδομένων.",
      "B": "Τον εντοπισμό και τη διατήρηση των πιο κρίσιμων πληροφοριών, μειώνοντας τον όγκο των δεδομένων.",
      "C": "Τη μετατροπή όλων των δεδομένων σε μορφή εικόνας για επεξεργασία από CNN.",
      "D": "Την προσθήκη τυχαίων χαρακτηριστικών για την αύξηση της πολυπλοκότητας."
    },
    "explanation": "Η εξαγωγή χαρακτηριστικών στοχεύει στην απλοποίηση των δεδομένων διατηρώντας μόνο τις πιο σημαντικές πληροφορίες. Αυτό γίνεται αφαιρώντας άχρηστες μεταβλητές και εντοπίζοντας τα κρίσιμα χαρακτηριστικά που επηρεάζουν τις προβλέψεις του μοντέλου."
  },
  {
    "question": "Ποιος είναι ο κύριος σκοπός της 'Μείωσης Διαστάσεων' (Dimensionality Reduction), όπως η μέθοδος PCA;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 99",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η αύξηση του αριθμού των μεταβλητών για καλύτερη ακρίβεια.",
      "B": "Η μετατροπή των δεδομένων σε ένα ενιαίο σύστημα μέτρησης.",
      "C": "Η κρυπτογράφηση των δεδομένων για λόγους ασφαλείας.",
      "D": "Η μείωση της πολυπλοκότητας των αλγορίθμων και η αποφυγή της υπερεκπαίδευσης (overfitting)."
    },
    "explanation": "Όταν τα δεδομένα έχουν πάρα πολλές μεταβλητές (υψηλή διαστατικότητα), οι αλγόριθμοι γίνονται πολύπλοκοι και μπορεί να εμφανίσουν υπερεκπαίδευση. Η μείωση διαστάσεων, όπως με την Ανάλυση Κύριων Συνιστωσών (PCA), βοηθά στη διατήρηση των σημαντικότερων πληροφοριών με λιγότερες μεταβλητές, βελτιώνοντας την απόδοση."
  },
  {
    "question": "Ποια από τις παρακάτω αρχές ΔΕΝ αποτελεί πυλώνα της αποτελεσματικής διακυβέρνησης δεδομένων (Data Governance) στην AI;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 100-101",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Ποιότητα και Ακεραιότητα Δεδομένων (Data Quality & Integrity).",
      "B": "Συμμόρφωση με Κανονισμούς και Νομοθεσία (Regulatory Compliance).",
      "C": "Μεγιστοποίηση της συλλογής δεδομένων ανεξαρτήτως πηγής και συναίνεσης.",
      "D": "Δεοντολογία στην Τεχνητή Νοημοσύνη και Δίκαιη Χρήση Δεδομένων (Ethical AI & Fair Data Usage)."
    },
    "explanation": "Η αποτελεσματική διακυβέρνηση δεδομένων βασίζεται στην ποιότητα, τη συμμόρφωση με νόμους όπως ο GDPR, και την ηθική χρήση. Η ανεξέλεγκτη συλλογή δεδομένων χωρίς έμφαση στη συναίνεση και τη δεοντολογία αντιβαίνει στις θεμελιώδεις αρχές της."
  },
  {
    "question": "Ποια στρατηγική ασφάλειας δεδομένων στοχεύει στην προστασία τους από μη εξουσιοδοτημένη πρόσβαση τόσο κατά την αποθήκευση όσο και κατά τη μεταφορά;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 101",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Κρυπτογράφηση Δεδομένων (Data Encryption).",
      "B": "Ανίχνευση Ανωμαλιών (Anomaly Detection).",
      "C": "Διαχωρισμός Συνόλων Δεδομένων (Data Splitting).",
      "D": "Κανονικοποίηση Δεδομένων (Data Normalization)."
    },
    "explanation": "Η κρυπτογράφηση δεδομένων αποτελεί τη βασική μέθοδο για την προστασία των πληροφοριών, καθώς τις καθιστά μη αναγνώσιμες σε όποιον δεν έχει το κατάλληλο 'κλειδί' αποκρυπτογράφησης. Εφαρμόζεται τόσο στα δεδομένα που είναι αποθηκευμένα (data at rest) όσο και σε αυτά που μεταφέρονται (data in transit)."
  },
  {
    "question": "Τι είναι η Πολυπαραγοντική Αυθεντικοποίηση (Multi-Factor Authentication - MFA) και γιατί είναι σημαντική για την ασφάλεια δεδομένων;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 101",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Μια μέθοδος που επιτρέπει σε πολλούς χρήστες να έχουν πρόσβαση στα ίδια δεδομένα ταυτόχρονα.",
      "B": "Μια διαδικασία που απαιτεί πολλαπλούς τρόπους επαλήθευσης ταυτότητας, προσθέτοντας ένα επιπλέον επίπεδο ασφάλειας.",
      "C": "Ένας αλγόριθμος που αναλύει δεδομένα από πολλούς διαφορετικούς παράγοντες.",
      "D": "Μια τεχνική αυτόματης δημιουργίας πολλαπλών αντιγράφων ασφαλείας."
    },
    "explanation": "Η MFA ενισχύει την ασφάλεια απαιτώντας από τον χρήστη να παρέχει τουλάχιστον δύο διαφορετικούς τύπους αποδεικτικών στοιχείων ταυτότητας (π.χ. κωδικός πρόσβασης και ένας κωδικός από το κινητό). Αυτό καθιστά πολύ πιο δύσκολη τη μη εξουσιοδοτημένη πρόσβαση, ακόμα και αν ένας από τους παράγοντες (π.χ. ο κωδικός) έχει υποκλαπεί."
  },
  {
    "question": "Ποια είναι μια από τις μεγαλύτερες προκλήσεις που συνδέονται με τον όγκο των δεδομένων (Big Data) και την υπολογιστική ισχύ στην AI;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 103-104",
      "paragraph": "1η & 2η παράγραφος"
    },
    "choices": {
      "A": "Η έλλειψη αλγορίθμων ικανών να επεξεργαστούν μεγάλα δεδομένα.",
      "B": "Η αδυναμία αποθήκευσης δεδομένων σε ψηφιακή μορφή.",
      "C": "Η απροθυμία των εταιρειών να συλλέξουν δεδομένα.",
      "D": "Η ανάγκη για τεράστιες ποσότητες δεδομένων και εξειδικευμένο υλικό για την εκπαίδευση προηγμένων μοντέλων."
    },
    "explanation": "Η εκθετική αύξηση των δεδομένων και οι απαιτήσεις των σύγχρονων αλγορίθμων, όπως της βαθιάς μάθησης, δημιουργούν σημαντικές προκλήσεις. Η εκπαίδευση αυτών των μοντέλων απαιτεί τεράστιους όγκους δεδομένων και ισχυρές υπολογιστικές υποδομές, όπως GPUs, αυξάνοντας το κόστος και την πολυπλοκότητα."
  },
  {
    "question": "Ποια λύση αναφέρεται στο κείμενο ως κρίσιμη για την αντιμετώπιση των προκλήσεων αποθήκευσης και επεξεργασίας μεγάλων όγκων δεδομένων;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 105",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η χρήση προσωπικών υπολογιστών για την εκπαίδευση μοντέλων.",
      "B": "Η διαγραφή των παλαιότερων δεδομένων για εξοικονόμηση χώρου.",
      "C": "Η υιοθέτηση του Υπολογιστικού Νέφους (Cloud Computing).",
      "D": "Η συμπίεση των δεδομένων σε μη αναστρέψιμη μορφή."
    },
    "explanation": "Το Υπολογιστικό Νέφος προσφέρει ευέλικτες, επεκτάσιμες και οικονομικά αποδοτικές λύσεις για την αποθήκευση και επεξεργασία τεράστιων όγκων δεδομένων. Επιτρέπει στις επιχειρήσεις να έχουν πρόσβαση σε ισχυρούς υπολογιστικούς πόρους χωρίς την ανάγκη για μεγάλες αρχικές επενδύσεις σε φυσικές υποδομές."
  },
  {
    "question": "Ποια τεχνολογία περιγράφεται ως η μελλοντική τάση που επιτρέπει σε μοντέλα AI να εκπαιδεύονται από κοινού σε πολλαπλές, αποκεντρωμένες συσκευές χωρίς να μετακινούνται τα δεδομένα;",
    "answer": "A",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 106",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Ομοσπονδιακή Μάθηση (Federated Learning).",
      "B": "Κεντρικοποιημένη Μάθηση (Centralized Learning).",
      "C": "Διακριτή Μάθηση (Discrete Learning).",
      "D": "Διαδικτυακή Μάθηση (Online Learning)."
    },
    "explanation": "Η Ομοσπονδιακή Μάθηση είναι μια τεχνική όπου το μοντέλο AI εκπαιδεύεται τοπικά σε κάθε συσκευή (π.χ. κινητό τηλέφωνο) και μόνο οι ενημερώσεις του μοντέλου, όχι τα πρωτογενή δεδομένα, αποστέλλονται σε έναν κεντρικό διακομιστή. Αυτό ενισχύει την ιδιωτικότητα και την ασφάλεια των δεδομένων."
  },
  {
    "question": "Στη μελέτη περίπτωσης για τη βελτιστοποίηση της εφοδιαστικής αλυσίδας (σελ. 109), ποιο ήταν το κύριο πρόβλημα που αντιμετώπιζε η εταιρεία λιανικής;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 109",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η κακή ποιότητα των προϊόντων της.",
      "B": "Η αδυναμία να προβλέψει με ακρίβεια τη ζήτηση των προϊόντων, οδηγώντας σε ελλείψεις ή πλεονάζοντα αποθέματα.",
      "C": "Οι συνεχείς κυβερνοεπιθέσεις στα συστήματά της.",
      "D": "Η έλλειψη εκπαιδευμένου προσωπικού για τα καταστήματα."
    },
    "explanation": "Το κεντρικό πρόβλημα ήταν η αναποτελεσματική διαχείριση αποθεμάτων λόγω ανακριβών προβλέψεων ζήτησης. Αυτό οδηγούσε είτε σε άδεια ράφια (χαμένες πωλήσεις) είτε σε υπερβολικό απόθεμα που αύξανε το κόστος αποθήκευσης."
  },
  {
    "question": "Ποια τεχνολογία αναφέρεται ως 'TinyML' και τι επιτρέπει;",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 107",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Μια τεχνική για τη δημιουργία πολύ μικρών αρχείων κειμένου.",
      "B": "Ένα κοινωνικό δίκτυο για προγραμματιστές AI.",
      "C": "Μια μέθοδος για την εκπαίδευση τεράστιων μοντέλων σε υπερυπολογιστές.",
      "D": "Την εκτέλεση αλγορίθμων μηχανικής μάθησης σε συσκευές χαμηλής κατανάλωσης ενέργειας, όπως αισθητήρες IoT."
    },
    "explanation": "Το TinyML (Tiny Machine Learning) είναι ένας αναδυόμενος τομέας που εστιάζει στη βελτιστοποίηση αλγορίθμων AI ώστε να μπορούν να λειτουργούν σε μικροελεγκτές και άλλες συσκευές με πολύ περιορισμένους υπολογιστικούς πόρους και χαμηλή κατανάλωση ενέργειας, φέρνοντας την 'ευφυΐα' απευθείας στην άκρη του δικτύου (edge)."
  },
  {
    "question": "Ποιος είναι ο ρόλος του 'Συνόλου Δοκιμής' (Test Set) κατά τον διαχωρισμό των δεδομένων;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 95",
      "paragraph": "7η παράγραφος"
    },
    "choices": {
      "A": "Η τελική αξιολόγηση της ικανότητας του μοντέλου να γενικεύει τις προβλέψεις του σε νέα, μη ορατά δεδομένα.",
      "B": "Η αρχική εκπαίδευση του μοντέλου για να μάθει τα βασικά πρότυπα.",
      "C": "Η ρύθμιση των υπερπαραμέτρων του μοντέλου κατά τη διάρκεια της εκπαίδευσης.",
      "D": "Η αποθήκευση των δεδομένων που κρίθηκαν ακατάλληλα κατά τον καθαρισμό."
    },
    "explanation": "Το Σύνολο Δοκιμής χρησιμοποιείται μία και μόνο φορά, στο τέλος της διαδικασίας, για να μετρηθεί η απόδοση του τελικού μοντέλου σε δεδομένα που δεν έχει 'δει' ποτέ ξανά. Αυτό δίνει μια αμερόληπτη εκτίμηση του πόσο καλά θα λειτουργήσει το μοντέλο σε πραγματικές συνθήκες."
  },
  {
    "question": "Τι είναι τα 'ημι-δομημένα' (semi-structured) δεδομένα;",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 91",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Δεδομένα που είναι κατά το ήμισυ κρυπτογραφημένα.",
      "B": "Δεδομένα που δεν ακολουθούν αυστηρή δομή πίνακα αλλά περιέχουν ετικέτες (tags) ή δείκτες για την οργάνωση των στοιχείων τους.",
      "C": "Δεδομένα που προέρχονται αποκλειστικά από αισθητήρες.",
      "D": "Δεδομένα που είναι πάντα λανθασμένα."
    },
    "explanation": "Τα ημι-δομημένα δεδομένα, όπως τα αρχεία JSON ή XML, βρίσκονται ανάμεσα στα δομημένα και τα μη δομημένα. Δεν έχουν την αυστηρή δομή μιας σχεσιακής βάσης δεδομένων, αλλά χρησιμοποιούν ετικέτες ή ιεραρχίες για να ομαδοποιήσουν και να περιγράψουν τα δεδομένα, καθιστώντας τα πιο ευέλικτα."
  },
  {
    "question": "Σύμφωνα με το κείμενο, ποια είναι η λειτουργία της 'κατηγοριοποίησης δεδομένων' (Encoding) κατά τον μετασχηματισμό τους;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 98",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η ταξινόμηση των δεδομένων σε φακέλους στον υπολογιστή.",
      "B": "Η συμπίεση των δεδομένων για μείωση του μεγέθους τους.",
      "C": "Η μετατροπή κατηγορικών μεταβλητών (π.χ. 'Αθήνα', 'Θεσσαλονίκη') σε αριθμητικές τιμές που μπορούν να επεξεργαστούν οι αλγόριθμοι.",
      "D": "Η απόκρυψη ευαίσθητων δεδομένων από τους χρήστες."
    },
    "explanation": "Οι αλγόριθμοι μηχανικής μάθησης λειτουργούν με αριθμούς. Η κατηγοριοποίηση (Encoding) είναι η διαδικασία μετατροπής μη αριθμητικών, κατηγορικών δεδομένων (όπως ονόματα πόλεων, τύποι προϊόντων κ.λπ.) σε μια αριθμητική αναπαράσταση, ώστε το μοντέλο να μπορεί να τα κατανοήσει και να τα επεξεργαστεί."
  },
  {
    "question": "Ποιος κανονισμός προστασίας δεδομένων ρυθμίζει τη χρήση προσωπικών δεδομένων στην Ευρωπαϊκή Ένωση και αναφέρεται στο κεφάλαιο;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 100",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "HIPAA",
      "B": "CCPA",
      "C": "AI Act",
      "D": "GDPR (General Data Protection Regulation)"
    },
    "explanation": "Ο Γενικός Κανονισμός για την Προστασία Δεδομένων (GDPR) είναι η νομοθεσία της Ευρωπαϊκής Ένωσης που θέτει αυστηρούς κανόνες για τη συλλογή, επεξεργασία και αποθήκευση προσωπικών δεδομένων, και αποτελεί βασικό πλαίσιο συμμόρφωσης για κάθε σύστημα AI που διαχειρίζεται δεδομένα Ευρωπαίων πολιτών."
  },
  {
    "question": "Ποιος είναι ο σκοπός των 'Incident Response Plans' που αναφέρονται στην ενότητα για την ασφάλεια δεδομένων;",
    "answer": "A",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 102",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Να παρέχουν ένα δομημένο σχέδιο για την αποτελεσματική διαχείριση περιστατικών κυβερνοασφάλειας, όπως οι παραβιάσεις δεδομένων.",
      "B": "Να προγραμματίζουν την καθημερινή συντήρηση των διακομιστών.",
      "C": "Να εκπαιδεύουν τα μοντέλα AI για να ανιχνεύουν σφάλματα στον κώδικά τους.",
      "D": "Να δημιουργούν αναφορές σχετικά με την απόδοση των εργαζομένων."
    },
    "explanation": "Τα Incident Response Plans είναι προκαθορισμένα σχέδια δράσης που ενεργοποιούνται όταν συμβεί ένα περιστατικό ασφαλείας. Σκοπός τους είναι η ταχεία και συντονισμένη αντίδραση για τον περιορισμό της ζημιάς, την ανάλυση της αιτίας και την αποκατάσταση της κανονικής λειτουργίας."
  },
  {
    "question": "Ποια από τις παρακάτω τεχνολογίες ΔΕΝ αναφέρεται ως λύση για τη βέλτιστη διαχείριση δεδομένων και υπολογιστικής ισχύος;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 105",
      "paragraph": "λίστα"
    },
    "choices": {
      "A": "Edge Computing",
      "B": "Βελτιστοποίηση Αλγορίθμων (Algorithm Optimization)",
      "C": "Εξειδικευμένο Υλικό (Specialized Hardware) όπως GPUs και TPUs",
      "D": "Χειροκίνητη εισαγωγή δεδομένων (Manual Data Entry)"
    },
    "explanation": "Οι λύσεις που προτείνονται για τη διαχείριση πόρων είναι τεχνολογικές, όπως το Edge Computing, η βελτιστοποίηση αλγορίθμων και η χρήση εξειδικευμένου υλικού. Η χειροκίνητη εισαγωγή δεδομένων δεν αποτελεί λύση για την αποδοτική διαχείριση μεγάλων όγκων δεδομένων."
  },
  {
    "question": "Σύμφωνα με το κείμενο, ποια είναι η βασική ιδέα πίσω από την 'Ενισχυμένη Νοημοσύνη' (Augmented Intelligence);",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 108",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η αντικατάσταση της ανθρώπινης νοημοσύνης από την τεχνητή.",
      "B": "Η συνεργασία μεταξύ ανθρώπων και συστημάτων AI, όπου η τεχνολογία ενισχύει τις ανθρώπινες ικανότητες.",
      "C": "Η δημιουργία βιολογικών ενισχύσεων στον ανθρώπινο εγκέφαλο.",
      "D": "Η αποκλειστική χρήση της AI για όλες τις αποφάσεις."
    },
    "explanation": "Η Ενισχυμένη Νοημοσύνη προωθεί ένα συνεργατικό μοντέλο. Αντί να αντικαθιστά τον άνθρωπο, η AI λειτουργεί ως ένα ισχυρό εργαλείο που ενισχύει τη λήψη αποφάσεων, την ανάλυση και τη δημιουργικότητα, συνδυάζοντας την υπολογιστική ισχύ της μηχανής με την κριτική σκέψη και τη διαίσθηση του ανθρώπου."
  },
  {
    "question": "Ποιο ήταν το αποτέλεσμα της χρήσης AI για την πρόβλεψη ζήτησης στη μελέτη περίπτωσης της εταιρείας λιανικής;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 110",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η εταιρεία αποφάσισε να κλείσει τα φυσικά της καταστήματα.",
      "B": "Το κόστος λειτουργίας της εφοδιαστικής αλυσίδας αυξήθηκε.",
      "C": "Βελτιώθηκε η ακρίβεια των προβλέψεων, μειώθηκαν οι ελλείψεις και το πλεονάζον απόθεμα.",
      "D": "Η εταιρεία σταμάτησε να χρησιμοποιεί τεχνολογία στα συστήματά της."
    },
    "explanation": "Η εφαρμογή του μοντέλου AI οδήγησε σε σημαντικά θετικά αποτελέσματα. Η εταιρεία κατάφερε να προβλέπει καλύτερα τη ζήτηση, γεγονός που οδήγησε σε βελτιστοποίηση των αποθεμάτων, μείωση του κόστους και καλύτερη εξυπηρέτηση των πελατών."
  },
  {
    "question": "Ποια διαδικασία περιγράφεται ως η μετατροπή μη δομημένων δεδομένων σε δομημένη μορφή;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 98",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Data Structuring",
      "B": "Data Deletion",
      "C": "Data Hiding",
      "D": "Data Simulation"
    },
    "explanation": "Το Data Structuring είναι η διαδικασία κατά την οποία τα μη δομημένα ή ημι-δομημένα δεδομένα μετατρέπονται σε μια οργανωμένη, δομημένη μορφή, όπως ένας πίνακας, ώστε να μπορούν να αναλυθούν πιο εύκολα από παραδοσιακά εργαλεία και αλγορίθμους."
  },
  {
    "question": "Ποιος είναι ο ρόλος του 'Συνόλου Επικύρωσης' (Validation Set) στην εκπαίδευση μοντέλων AI;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 95",
      "paragraph": "7η παράγραφος"
    },
    "choices": {
      "A": "Χρησιμοποιείται για την τελική μέτρηση της απόδοσης του μοντέλου σε εντελώς νέα δεδομένα.",
      "B": "Είναι το κύριο σύνολο δεδομένων που χρησιμοποιείται για την εκμάθηση των προτύπων από το μοντέλο.",
      "C": "Περιέχει τα δεδομένα που απορρίφθηκαν κατά τον καθαρισμό.",
      "D": "Βοηθά στη ρύθμιση των υπερπαραμέτρων του μοντέλου και στην αποτροπή της υπερεκπαίδευσης."
    },
    "explanation": "Το Validation Set χρησιμοποιείται κατά τη διάρκεια της εκπαίδευσης για να 'τσεκάρει' περιοδικά την απόδοση του μοντέλου και να βοηθήσει στη βελτιστοποίηση των ρυθμίσεών του (υπερπαράμετροι). Η παρακολούθηση της απόδοσης σε αυτό το σύνολο βοηθά να αποφευχθεί το φαινόμενο της υπερεκπαίδευσης (overfitting), όπου το μοντέλο μαθαίνει 'απ' έξω' τα δεδομένα εκπαίδευσης αλλά δεν μπορεί να γενικεύσει."
  },
  {
    "question": "Γιατί η 'ποιότητα των δεδομένων' θεωρείται πιο σημαντική από την 'ποσότητα των δεδομένων' για την εκπαίδευση μοντέλων AI;",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 89",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Επειδή τα ποιοτικά δεδομένα απαιτούν λιγότερο χώρο αποθήκευσης.",
      "B": "Επειδή δεδομένα χαμηλής ποιότητας, ακόμα και σε μεγάλες ποσότητες, θα οδηγήσουν σε ανακριβή και αναξιόπιστα μοντέλα (Garbage In, Garbage Out).",
      "C": "Επειδή τα ποιοτικά δεδομένα είναι πάντα δωρεάν.",
      "D": "Επειδή η ποσότητα δεν παίζει κανέναν απολύτως ρόλο στην εκπαίδευση."
    },
    "explanation": "Η αρχή 'Garbage In, Garbage Out' (Σκουπίδια Μέσα, Σκουπίδια Έξω) είναι θεμελιώδης στην AI. Ένα μοντέλο είναι τόσο καλό όσο και τα δεδομένα με τα οποία εκπαιδεύεται. Μεγάλοι όγκοι ανακριβών, ελλιπών ή μεροληπτικών δεδομένων θα οδηγήσουν αναπόφευκτα σε ένα μοντέλο που παράγει λανθασμένα αποτελέσματα, ανεξάρτητα από την πολυπλοκότητα του αλγορίθμου."
  },
  {
    "question": "Ποια από τις παρακάτω ΔΕΝ είναι πρόκληση στον καθαρισμό και τη διαχείριση δεδομένων, σύμφωνα με το κείμενο;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 96",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η υπερβολικά γρήγορη ταχύτητα των σύγχρονων υπολογιστών.",
      "B": "Ο τεράστιος όγκος των δεδομένων που πρέπει να επεξεργαστούν.",
      "C": "Οι προκαταλήψεις (biases) που μπορεί να υπάρχουν στα δεδομένα.",
      "D": "Η ανάγκη για αποδοτικές λύσεις αποθήκευσης, όπως το υπολογιστικό νέφος."
    },
    "explanation": "Το κείμενο αναφέρει τον όγκο των δεδομένων και τις ενσωματωμένες προκαταλήψεις ως κύριες προκλήσεις. Η γρήγορη ταχύτητα των υπολογιστών είναι πλεονέκτημα και όχι πρόκληση στη διαχείριση δεδομένων."
  },
  {
    "question": "Πώς ορίζεται η 'Ανάλυση Δεδομένων' (Data Analysis) στο πλαίσιο της τεχνητής νοημοσύνης;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 97",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Ως η διαδικασία δημιουργίας αντιγράφων ασφαλείας των δεδομένων.",
      "B": "Ως η διαδικασία διαγραφής περιττών δεδομένων.",
      "C": "Ως η διαδικασία εξέτασης, καθαρισμού και μοντελοποίησης δεδομένων για την εξαγωγή χρήσιμων πληροφοριών και την υποστήριξη αποφάσεων.",
      "D": "Ως η πώληση των δεδομένων σε διαφημιστικές εταιρείες."
    },
    "explanation": "Η ανάλυση δεδομένων είναι μια ευρύτερη διαδικασία που περιλαμβάνει την επιθεώρηση και επεξεργασία των δεδομένων με σκοπό να ανακαλυφθούν κρυμμένα μοτίβα, συσχετίσεις και άλλες χρήσιμες πληροφορίες που μπορούν να βοηθήσουν στη λήψη στρατηγικών αποφάσεων."
  },
  {
    "question": "Ποιος είναι ο σκοπός της 'κανονικοποίησης' (Normalization) στον μετασχηματισμό δεδομένων;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 98",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η διαγραφή όλων των αριθμητικών τιμών.",
      "B": "Η μετατροπή των τιμών ώστε να βρίσκονται σε μια κοινή κλίμακα, χωρίς να αλλοιώνεται η μεταξύ τους αναλογία.",
      "C": "Η αρχειοθέτηση των δεδομένων σε φυσικά αρχεία.",
      "D": "Η αύξηση της απόκλισης μεταξύ των τιμών των δεδομένων."
    },
    "explanation": "Η κανονικοποίηση μετασχηματίζει τις αριθμητικές στήλες σε μια κοινή κλίμακα (π.χ., από 0 έως 1), κάτι που είναι απαραίτητο για πολλούς αλγορίθμους μηχανικής μάθησης. Αυτό διασφαλίζει ότι καμία μεταβλητή δεν θα κυριαρχήσει στην ανάλυση απλώς και μόνο επειδή έχει μεγαλύτερο εύρος τιμών."
  },
  {
    "question": "Ποιος νόμος στις ΗΠΑ, αντίστοιχος του GDPR, αναφέρεται στο κείμενο για την προστασία των προσωπικών πληροφοριών των καταναλωτών;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 100",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "The Patriot Act",
      "B": "The Freedom of Information Act",
      "C": "HIPAA",
      "D": "CCPA (California Consumer Privacy Act)"
    },
    "explanation": "Ο CCPA είναι ένας νόμος της Καλιφόρνια που δίνει στους καταναλωτές περισσότερο έλεγχο πάνω στα προσωπικά δεδομένα που συλλέγουν οι εταιρείες γι' αυτούς. Συχνά αναφέρεται ως το αμερικανικό αντίστοιχο του GDPR της ΕΕ."
  },
  {
    "question": "Ποια είναι η κύρια λειτουργία του 'Role-Based Access Control' (RBAC) στην ασφάλεια δεδομένων;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 101",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Να διασφαλίζει ότι κάθε χρήστης έχει πρόσβαση μόνο στα δεδομένα που είναι απολύτως απαραίτητα για τον ρόλο του.",
      "B": "Να αναθέτει τυχαίους ρόλους στους χρήστες κάθε μέρα.",
      "C": "Να ελέγχει την απόδοση των ηθοποιών σε ένα θεατρικό έργο.",
      "D": "Να επιτρέπει σε όλους τους χρήστες να έχουν πλήρη πρόσβαση σε όλα τα δεδομένα."
    },
    "explanation": "Το RBAC είναι μια θεμελιώδης αρχή ασφάλειας που περιορίζει την πρόσβαση στα συστήματα και τα δεδομένα ανάλογα με τον ρόλο και τις αρμοδιότητες ενός ατόμου μέσα σε έναν οργανισμό. Αυτό ελαχιστοποιεί τον κίνδυνο από τυχαία ή κακόβουλη έκθεση ευαίσθητων πληροφοριών."
  },
  {
    "question": "Γιατί η 'Δεοντολογία στην Τεχνητή Νοημοσύνη' είναι σημαντική στη διακυβέρνηση δεδομένων;",
    "answer": "C",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 101",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Για να κάνει τους αλγορίθμους πιο αργούς και πιο προσεκτικούς.",
      "B": "Επειδή απαιτείται από όλες τις πλατφόρμες κοινωνικής δικτύωσης.",
      "C": "Για να διασφαλιστεί ότι τα συστήματα AI λειτουργούν με διαφάνεια, χωρίς προκαταλήψεις και δεν οδηγούν σε άδικες διακρίσεις.",
      "D": "Για να αυξήσει το κέρδος των εταιρειών που αναπτύσσουν AI."
    },
    "explanation": "Η δεοντολογία στην AI εστιάζει στην αντιμετώπιση ηθικών ζητημάτων όπως οι προκαταλήψεις και οι διακρίσεις. Η σωστή διακυβέρνηση δεδομένων πρέπει να ενσωματώνει ηθικές πρακτικές για να εξασφαλίσει ότι τα μοντέλα που παράγονται είναι δίκαια και δεν βλάπτουν άτομα ή κοινωνικές ομάδες, όπως φαίνεται στο παράδειγμα του συστήματος προσλήψεων."
  },
  {
    "question": "Τι είναι τα 'data-centric' AI συστήματα, σύμφωνα με τις μελλοντικές τάσεις;",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 107",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Συστήματα που εστιάζουν αποκλειστικά στη βελτιστοποίηση του κώδικα των αλγορίθμων.",
      "B": "Μια προσέγγιση όπου η έμφαση δίνεται στη συστηματική βελτίωση της ποιότητας των δεδομένων αντί για τη συνεχή αλλαγή του μοντέλου.",
      "C": "Συστήματα που λειτουργούν χωρίς καθόλου δεδομένα.",
      "D": "Μοντέλα που μπορούν να αλλάζουν αυτόματα τον αλγόριθμό τους κάθε μέρα."
    },
    "explanation": "Η προσέγγιση 'data-centric' AI αναγνωρίζει ότι η ποιότητα των δεδομένων είναι ο πιο κρίσιμος παράγοντας για την απόδοση ενός μοντέλου. Αντί να εστιάζουν συνεχώς στην εύρεση ενός καλύτερου αλγορίθμου (model-centric), οι μηχανικοί επικεντρώνονται στον καθαρισμό, την επισήμανση και τη βελτίωση του συνόλου δεδομένων, θεωρώντας το μοντέλο ως σταθερό."
  },
  {
    "question": "Ποιος τύπος ανάλυσης δεδομένων χρησιμοποιεί ιστορικά δεδομένα για να απαντήσει στο ερώτημα «Γιατί συνέβη αυτό;»;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 97",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Διαγνωστική Ανάλυση (Diagnostic Analysis).",
      "B": "Προγνωστική Ανάλυση (Predictive Analysis).",
      "C": "Περιγραφική Ανάλυση (Descriptive Analysis).",
      "D": "Κατευθυντήρια Ανάλυση (Prescriptive Analysis)."
    },
    "explanation": "Η Διαγνωστική Ανάλυση πηγαίνει ένα βήμα παραπέρα από την περιγραφική, προσπαθώντας να κατανοήσει τις αιτίες πίσω από τα γεγονότα που συνέβησαν. Αναλύει τα δεδομένα για να εντοπίσει τις σχέσεις αιτίου-αποτελέσματος."
  },
  {
    "question": "Ποιος είναι ο κύριος στόχος των ημιδιαφανών μοντέλων (interpretable models) στην AI;",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 108",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Να είναι τα πιο γρήγορα μοντέλα στην αγορά.",
      "B": "Να λειτουργούν μόνο με μικρά σύνολα δεδομένων.",
      "C": "Να είναι τα πιο πολύπλοκα και ακατανόητα μοντέλα.",
      "D": "Να επιτρέπουν στους ανθρώπους να κατανοούν πώς και γιατί ένα μοντέλο έλαβε μια συγκεκριμένη απόφαση (Explainable AI - XAI)."
    },
    "explanation": "Καθώς τα μοντέλα AI γίνονται πιο πολύπλοκα ('μαύρα κουτιά'), η ανάγκη για διαφάνεια αυξάνεται. Τα ημιδιαφανή μοντέλα, ή η Εξηγήσιμη AI (XAI), στοχεύουν στο να κάνουν τις αποφάσεις των αλγορίθμων κατανοητές στους ανθρώπους, κάτι που είναι κρίσιμο για την εμπιστοσύνη και τη λογοδοσία, ειδικά σε τομείς όπως η ιατρική και τα οικονομικά."
  },
  {
    "question": "Στη μελέτη περίπτωσης, ποια εξωτερικά δεδομένα χρησιμοποίησε η εταιρεία για να βελτιώσει τις προβλέψεις ζήτησης;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 109",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Δεδομένα από το χρηματιστήριο.",
      "B": "Δεδομένα καιρού, τοπικές αργίες και δημογραφικά στοιχεία.",
      "C": "Κριτικές ταινιών από το διαδίκτυο.",
      "D": "Αποτελέσματα αθλητικών αγώνων."
    },
    "explanation": "Για να βελτιώσει τις προβλέψεις της, η εταιρεία συνδύασε τα εσωτερικά της δεδομένα πωλήσεων με εξωτερικούς παράγοντες που επηρεάζουν την αγοραστική συμπεριφορά, όπως ο καιρός, οι αργίες, και τα δημογραφικά χαρακτηριστικά της κάθε περιοχής."
  },
  {
    "question": "Ποιος τύπος δεδομένων περιλαμβάνει αρχεία ήχου, βίντεο και αναρτήσεις σε μέσα κοινωνικής δικτύωσης;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 91",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Δομημένα δεδομένα.",
      "B": "Ημι-δομημένα δεδομένα.",
      "C": "Μη δομημένα δεδομένα.",
      "D": "Κανονικοποιημένα δεδομένα."
    },
    "explanation": "Τα αρχεία πολυμέσων όπως ο ήχος και το βίντεο, καθώς και το ελεύθερο κείμενο από τα social media, δεν έχουν προκαθορισμένη, άκαμπτη δομή. Ως εκ τούτου, ταξινομούνται ως μη δομημένα δεδομένα, η ανάλυση των οποίων απαιτεί προηγμένες τεχνικές AI."
  },
  {
    "question": "Ποια τεχνική χρησιμοποιείται για την αντιμετώπιση ελλιπών τιμών σε ένα σύνολο δεδομένων;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 94",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Η συμπλήρωση των κενών με τον μέσο όρο ή τη διάμεσο της στήλης.",
      "B": "Η διαγραφή ολόκληρου του συνόλου δεδομένων.",
      "C": "Η αντικατάσταση των κενών με τυχαίο κείμενο.",
      "D": "Η αγνόηση των κενών τιμών κατά την εκπαίδευση του μοντέλου."
    },
    "explanation": "Μια κοινή και απλή μέθοδος για την αντιμετώπιση των ελλιπών αριθμητικών δεδομένων είναι η 'imputation', όπου η κενή τιμή αντικαθίσταται από μια στατιστική τιμή που υπολογίζεται από τις υπόλοιπες τιμές της ίδιας στήλης, όπως ο μέσος όρος ή η διάμεσος."
  },
  {
    "question": "Τι περιλαμβάνει η 'Ανάλυση Κύριων Συνιστωσών' (Principal Component Analysis - PCA);",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 99",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Την ανάλυση μόνο των δύο πρώτων στηλών ενός πίνακα δεδομένων.",
      "B": "Μια μέθοδο μείωσης διαστάσεων που μετατρέπει τις αρχικές μεταβλητές σε ένα νέο, μικρότερο σύνολο μη συσχετισμένων μεταβλητών.",
      "C": "Τον υπολογισμό του μέσου όρου όλων των δεδομένων.",
      "D": "Τον εντοπισμό των κύριων ανταγωνιστών μιας επιχείρησης."
    },
    "explanation": "Η PCA είναι μια ισχυρή στατιστική τεχνική που χρησιμοποιείται για τη μείωση της διαστατικότητας. Λειτουργεί δημιουργώντας νέες μεταβλητές, τις 'κύριες συνιστώσες', οι οποίες είναι γραμμικοί συνδυασμοί των αρχικών και αποτυπώνουν το μεγαλύτερο μέρος της διακύμανσης των δεδομένων με μικρότερο αριθμό μεταβλητών."
  },
  {
    "question": "Ποια είναι η βασική αρχή λειτουργίας της τεχνολογίας Edge Computing;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 105",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Όλες οι υπολογιστικές διεργασίες γίνονται σε έναν κεντρικό διακομιστή στο cloud.",
      "B": "Τα δεδομένα αποθηκεύονται μόνο στις άκρες των σκληρών δίσκων.",
      "C": "Η επεξεργασία γίνεται μόνο από υπολογιστές που βρίσκονται στα γεωγραφικά άκρα μιας χώρας.",
      "D": "Η επεξεργασία των δεδομένων γίνεται τοπικά, κοντά στην πηγή παραγωγής τους, αντί να αποστέλλονται στο cloud."
    },
    "explanation": "Το Edge Computing μεταφέρει την υπολογιστική ισχύ από το κεντρικοποιημένο cloud πιο κοντά στις συσκευές που παράγουν τα δεδομένα (π.χ. αισθητήρες, κάμερες). Αυτό μειώνει την καθυστέρηση (latency), εξοικονομεί εύρος ζώνης και επιτρέπει ταχύτερες αποφάσεις σε πραγματικό χρόνο."
  },
  {
    "question": "Ποιο από τα παρακάτω ΔΕΝ αποτελεί τύπο ανάλυσης δεδομένων που αναφέρεται στο κείμενο;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 97",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Ιστορική Ανάλυση (Historical Analysis).",
      "B": "Περιγραφική Ανάλυση (Descriptive Analysis).",
      "C": "Προγνωστική Ανάλυση (Predictive Analysis).",
      "D": "Διαγνωστική Ανάλυση (Diagnostic Analysis)."
    },
    "explanation": "Το κείμενο περιγράφει τέσσερις τύπους ανάλυσης: Περιγραφική, Διαγνωστική, Προγνωστική και Κατευθυντήρια. Ο όρος 'Ιστορική Ανάλυση' δεν αναφέρεται ως διακριτή κατηγορία σε αυτή την ταξινόμηση, αν και όλοι οι τύποι βασίζονται σε ιστορικά δεδομένα."
  },
  {
    "question": "Ποιος είναι ο στόχος του HIPAA, που αναφέρεται στην ενότητα για τη συμμόρφωση με κανονισμούς;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 100",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Η προστασία των οικονομικών συναλλαγών.",
      "B": "Η διασφάλιση της ελευθερίας του λόγου στο διαδίκτυο.",
      "C": "Η διασφάλιση της προστασίας των ιατρικών δεδομένων των ασθενών.",
      "D": "Ο έλεγχος της ποιότητας των τροφίμων και των φαρμάκων."
    },
    "explanation": "Ο νόμος HIPAA (Health Insurance Portability and Accountability Act) είναι μια ομοσπονδιακή νομοθεσία των ΗΠΑ που θέτει πρότυπα για την προστασία των ευαίσθητων δεδομένων υγείας των ασθενών από το να αποκαλυφθούν χωρίς τη συγκατάθεσή τους."
  },
  {
    "question": "Πώς συνέβαλε το εξειδικευμένο υλικό (GPUs, TPUs) στην εξέλιξη της AI;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 105",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Μείωσε την ανάγκη για μεγάλα σύνολα δεδομένων.",
      "B": "Επιτάχυνε δραματικά την εκπαίδευση πολύπλοκων μοντέλων βαθιάς μάθησης, κάνοντας εφικτές εφαρμογές που παλαιότερα ήταν αδύνατες.",
      "C": "Κατέστησε τους αλγόριθμους λιγότερο ακριβείς.",
      "D": "Χρησιμοποιείται αποκλειστικά για την αποθήκευση δεδομένων."
    },
    "explanation": "Οι μονάδες επεξεργασίας γραφικών (GPUs) και οι εξειδικευμένες μονάδες όπως οι TPUs (Tensor Processing Units) είναι σχεδιασμένες για να εκτελούν μαζικά παράλληλους υπολογισμούς. Αυτό τις καθιστά ιδανικές για τις απαιτητικές μαθηματικές πράξεις της εκπαίδευσης νευρωνικών δικτύων, μειώνοντας τον χρόνο εκπαίδευσης από εβδομάδες ή μήνες σε ημέρες ή ώρες."
  },
  {
    "question": "Τι είναι τα 'Συνθετικά Δεδομένα' (Synthetic Data) και ποια ανάγκη καλύπτουν;",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 107",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Δεδομένα που συλλέγονται από συνθετικές ίνες.",
      "B": "Πραγματικά δεδομένα που έχουν απλώς μετονομαστεί.",
      "C": "Δεδομένα που περιγράφουν τη διαδικασία της φωτοσύνθεσης.",
      "D": "Τεχνητά παραγόμενα δεδομένα που μιμούνται τις στατιστικές ιδιότητες των πραγματικών, χρήσιμα όταν τα πραγματικά δεδομένα είναι σπάνια ή ευαίσθητα."
    },
    "explanation": "Τα συνθετικά δεδομένα δημιουργούνται αλγοριθμικά και όχι από πραγματικά γεγονότα. Χρησιμοποιούνται για την εκπαίδευση μοντέλων AI σε σενάρια όπου η συλλογή πραγματικών δεδομένων είναι δύσκολη, δαπανηρή ή εγείρει ζητήματα ιδιωτικότητας (π.χ. ιατρικά δεδομένα)."
  },
  {
    "question": "Σε ποια κατηγορία ανήκει ένα σύνολο δεδομένων που περιέχει τις ημερήσιες πωλήσεις ενός καταστήματος σε μορφή πίνακα;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 91",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Δομημένα δεδομένα.",
      "B": "Μη δομημένα δεδομένα.",
      "C": "Ημι-δομημένα δεδομένα.",
      "D": "Ανύπαρκτα δεδομένα."
    },
    "explanation": "Ένας πίνακας με στήλες (π.χ. 'Ημερομηνία', 'Προϊόν', 'Ποσότητα', 'Τιμή') και γραμμές (κάθε πώληση) αποτελεί την κλασική περίπτωση δομημένων δεδομένων, καθώς ακολουθεί ένα αυστηρό, προκαθορισμένο σχήμα."
  },
  {
    "question": "Ποιος είναι ο κύριος κίνδυνος από τις 'ακραίες τιμές' (outliers) σε ένα σύνολο δεδομένων;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 95",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Μπορούν να κάνουν το σύνολο δεδομένων να φαίνεται πιο ενδιαφέρον.",
      "B": "Βελτιώνουν πάντα την ακρίβεια του μοντέλου.",
      "C": "Μπορούν να διαστρεβλώσουν τις προβλέψεις και τα αποτελέσματα των μοντέλων τεχνητής νοημοσύνης.",
      "D": "Δεν έχουν καμία απολύτως επίδραση στα μοντέλα."
    },
    "explanation": "Οι ακραίες τιμές είναι σημεία δεδομένων που διαφέρουν σημαντικά από τα υπόλοιπα. Αν δεν αντιμετωπιστούν, μπορούν να επηρεάσουν δυσανάλογα την εκπαίδευση ενός μοντέλου, 'τραβώντας' τις προβλέψεις προς το μέρος τους και οδηγώντας σε ανακριβή αποτελέσματα για την πλειοψηφία των κανονικών δεδομένων."
  },
  {
    "question": "Για ποιο λόγο η 'Ποιότητα και Ακεραιότητα Δεδομένων' είναι θεμελιώδης αρχή της διακυβέρνησης δεδομένων;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 100",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Για να αυξάνεται το μέγεθος των βάσεων δεδομένων.",
      "B": "Επειδή η απόδοση και η αξιοπιστία των αλγορίθμων AI εξαρτώνται άμεσα από την ακρίβεια των δεδομένων με τα οποία εκπαιδεύονται.",
      "C": "Γιατί καθιστά τα δεδομένα πιο δύσκολα στην πρόσβαση.",
      "D": "Επειδή μειώνει την ανάγκη για ασφάλεια των δεδομένων."
    },
    "explanation": "Η διασφάλιση της ποιότητας και της ακεραιότητας σημαίνει ότι τα δεδομένα είναι ακριβή, συνεπή και αξιόπιστα. Χωρίς αυτή τη βάση, οποιοδήποτε μοντέλο AI χτιστεί πάνω σε αυτά τα δεδομένα θα είναι εγγενώς ελαττωματικό, οδηγώντας σε λάθος συμπεράσματα και αποφάσεις."
  },
  {
    "question": "Ποια από τις παρακάτω πηγές δεδομένων θεωρείται 'εξωτερική πηγή' (External Source);",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 92",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η βάση δεδομένων με τους υπαλλήλους της εταιρείας.",
      "B": "Τα αρχεία πωλήσεων από το σύστημα ταμείου.",
      "C": "Τα δεδομένα από τους αισθητήρες της γραμμής παραγωγής.",
      "D": "Δημόσια διαθέσιμα σύνολα δεδομένων από κυβερνητικούς οργανισμούς."
    },
    "explanation": "Οι εξωτερικές πηγές περιλαμβάνουν δεδομένα που προέρχονται από οντότητες εκτός του οργανισμού. Τα δημόσια σύνολα δεδομένων, όπως αυτά που παρέχονται από κυβερνήσεις (π.χ. δημογραφικά, οικονομικά στοιχεία), είναι ένα χαρακτηριστικό παράδειγμα."
  },
  {
    "question": "Ποιος τύπος ανάλυσης δεδομένων στοχεύει να προβλέψει μελλοντικά αποτελέσματα και τάσεις;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 97",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Προγνωστική Ανάλυση (Predictive Analysis).",
      "B": "Περιγραφική Ανάλυση (Descriptive Analysis).",
      "C": "Διαγνωστική Ανάλυση (Diagnostic Analysis).",
      "D": "Ανάλυση Κειμένου (Text Analysis)."
    },
    "explanation": "Η Προγνωστική Ανάλυση χρησιμοποιεί τεχνικές από τη στατιστική και τη μηχανική μάθηση για να αναλύσει τρέχοντα και ιστορικά δεδομένα με σκοπό να κάνει προβλέψεις για το μέλλον. Απαντά στο ερώτημα 'Τι είναι πιθανό να συμβεί;'."
  },
  {
    "question": "Στη μελέτη περίπτωσης για την εφοδιαστική αλυσίδα, ποια ήταν η λύση που εφάρμοσε η εταιρεία;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 110",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Προσέλαβε περισσότερους υπαλλήλους για τις αποθήκες.",
      "B": "Αύξησε τις τιμές όλων των προϊόντων της.",
      "C": "Ανέπτυξε ένα προσαρμοσμένο μοντέλο τεχνητής νοημοσύνης για την πρόβλεψη της ζήτησης.",
      "D": "Σταμάτησε να πουλά τα προϊόντα με τη χαμηλότερη ζήτηση."
    },
    "explanation": "Η εταιρεία αντιμετώπισε το πρόβλημα των ανακριβών προβλέψεων αναπτύσσοντας ένα μοντέλο AI. Αυτό το μοντέλο ανέλυε ιστορικά δεδομένα πωλήσεων σε συνδυασμό με εξωτερικούς παράγοντες για να παράγει πολύ πιο ακριβείς προβλέψεις για τη μελλοντική ζήτηση."
  },
  {
    "question": "Ποιος είναι ο σκοπός της κλιμάκωσης τιμών (Scaling) στον μετασχηματισμό δεδομένων;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 98",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η αύξηση της κλίμακας των γραφικών σε μια εικόνα.",
      "B": "Η τοποθέτηση των τιμών των μεταβλητών σε ένα συγκεκριμένο εύρος (π.χ. 0-1) για να έχουν ίση βαρύτητα στην ανάλυση.",
      "C": "Η μέτρηση του βάρους ενός αντικειμένου σε μια κλίμακα.",
      "D": "Η μετατροπή όλων των αριθμών σε ακέραιους."
    },
    "explanation": "Η κλιμάκωση (scaling) είναι μια μορφή κανονικοποίησης. Είναι σημαντική όταν οι μεταβλητές έχουν πολύ διαφορετικά εύρη τιμών (π.χ. ηλικία 20-70 και εισόδημα 10,000-100,000). Χωρίς κλιμάκωση, οι αλγόριθμοι μπορεί να δώσουν λανθασμένα μεγαλύτερη σημασία στη μεταβλητή με το μεγαλύτερο εύρος τιμών."
  },
  {
    "question": "Ποια πρόκληση της διαχείρισης δεδομένων αντιμετωπίζεται με τεχνικές εξισορρόπησης όπως το oversampling και το undersampling;",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 95",
      "paragraph": "6η παράγραφος"
    },
    "choices": {
      "A": "Οι ελλιπείς τιμές στα δεδομένα.",
      "B": "Ο μεγάλος όγκος των δεδομένων.",
      "C": "Τα τυπογραφικά λάθη στα κείμενα.",
      "D": "Οι προκαταλήψεις και οι ανισορροπίες μεταξύ των κατηγοριών στα δεδομένα."
    },
    "explanation": "Όταν μια κατηγορία δεδομένων είναι πολύ πιο σπάνια από άλλες (π.χ. ανίχνευση απάτης), το μοντέλο μπορεί να μάθει να αγνοεί τη σπάνια κατηγορία. Τεχνικές όπως το oversampling (δημιουργία αντιγράφων της σπάνιας κατηγορίας) ή το undersampling (διαγραφή δειγμάτων από την πολυπληθή κατηγορία) χρησιμοποιούνται για να εξισορροπήσουν το σύνολο δεδομένων και να βελτιώσουν την απόδοση του μοντέλου."
  },
  {
    "question": "Ποια μέθοδος καθαρισμού δεδομένων περιλαμβάνει την ενοποίηση μορφών ημερομηνίας ή μονάδων μέτρησης;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 94",
      "paragraph": "5η παράγραφος"
    },
    "choices": {
      "A": "Κανονικοποίηση τιμών.",
      "B": "Ανίχνευση ακραίων τιμών.",
      "C": "Χειρισμός ελλιπών δεδομένων.",
      "D": "Διαγραφή διπλότυπων εγγραφών."
    },
    "explanation": "Η κανονικοποίηση τιμών στο πλαίσιο της διόρθωσης σφαλμάτων στοχεύει στη δημιουργία ομοιομορφίας. Για παράδειγμα, αν κάποιες ημερομηνίες είναι σε μορφή 'DD/MM/YYYY' και άλλες σε 'MM-DD-YY', η κανονικοποίηση θα τις μετατρέψει όλες σε μια ενιαία, συνεπή μορφή."
  },
  {
    "question": "Ποια είναι η τελική φάση του κύκλου ζωής της διαχείρισης δεδομένων στην AI;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 90",
      "paragraph": "2η παράγραφος (Εικόνα)"
    },
    "choices": {
      "A": "Συλλογή Δεδομένων",
      "B": "Αξιοποίηση & Οπτικοποίηση",
      "C": "Καθαρισμός Δεδομένων",
      "D": "Αποθήκευση Δεδομένων"
    },
    "explanation": "Σύμφωνα με το διάγραμμα του κύκλου ζωής, η διαδικασία ολοκληρώνεται με την αξιοποίηση των αποτελεσμάτων που παράγει το μοντέλο AI και την οπτικοποίησή τους, ώστε να γίνουν κατανοητά και να υποστηρίξουν τη λήψη αποφάσεων."
  },
  {
    "question": "Η αρχή 'Garbage In, Garbage Out' τονίζει τη σημασία ποιου παράγοντα στην Τεχνητή Νοημοσύνη;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 89",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Της ταχύτητας του επεξεργαστή.",
      "B": "Της πολυπλοκότητας του αλγορίθμου.",
      "C": "Της ποιότητας των δεδομένων εκπαίδευσης.",
      "D": "Της ποσότητας της μνήμης RAM."
    },
    "explanation": "Αυτή η φράση-κλειδί υπογραμμίζει ότι η ποιότητα της εξόδου ενός συστήματος AI είναι άρρηκτα συνδεδεμένη με την ποιότητα της εισόδου. Εάν το μοντέλο τροφοδοτηθεί με ανακριβή ή μεροληπτικά δεδομένα ('σκουπίδια'), θα παράγει αναπόφευκτα ανακριβή ή μεροληπτικά αποτελέσματα ('σκουπίδια')."
  },
  {
    "question": "Ποια είναι μια από τις κύριες προκλήσεις της ασφάλειας δεδομένων στην AI;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 102",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η δυσκολία στην εύρεση δεδομένων.",
      "B": "Η έλλειψη αλγορίθμων κρυπτογράφησης.",
      "C": "Η αργή ταχύτητα των δικτύων.",
      "D": "Η ανίχνευση και η έγκαιρη αντίδραση σε κυβερνοεπιθέσεις και παραβιάσεις δεδομένων."
    },
    "explanation": "Η προστασία των συστημάτων AI από κακόβουλες επιθέσεις είναι μια συνεχής πρόκληση. Οι οργανισμοί πρέπει να εφαρμόζουν συστήματα που εντοπίζουν απειλές σε πραγματικό χρόνο και να έχουν έτοιμα σχέδια αντιμετώπισης (Incident Response Plans) για να διαχειριστούν αποτελεσματικά τυχόν παραβιάσεις."
  },
  {
    "question": "Ποια τεχνική περιλαμβάνει την αφαίρεση εγγραφών με πολλά ελλιπή πεδία από ένα σύνολο δεδομένων;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 94",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Χειρισμός ελλιπών δεδομένων.",
      "B": "Ανίχνευση ακραίων τιμών.",
      "C": "Κλιμάκωση τιμών.",
      "D": "Εξαγωγή χαρακτηριστικών."
    },
    "explanation": "Μια από τις στρατηγικές για τον χειρισμό ελλιπών δεδομένων είναι η απλή αφαίρεση των γραμμών (εγγραφών) που έχουν λειψές τιμές, ειδικά αν ο αριθμός των ελλιπών πεδίων είναι μεγάλος και η συμπλήρωσή τους θα ήταν αναξιόπιστη."
  },
  {
    "question": "Ποιο είναι το όφελος της βελτιστοποίησης αλγορίθμων (Algorithm Optimization) στη διαχείριση υπολογιστικής ισχύος;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 105",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Αυξάνει πάντα τον όγκο των δεδομένων που απαιτούνται.",
      "B": "Μειώνει την υπολογιστική πολυπλοκότητα και τις απαιτήσεις σε πόρους, κάνοντας τα μοντέλα πιο αποδοτικά.",
      "C": "Κάνει τους αλγορίθμους να λειτουργούν μόνο σε εξειδικευμένο υλικό.",
      "D": "Εξασφαλίζει ότι ο αλγόριθμος θα δίνει πάντα 100% ακριβή αποτελέσματα."
    },
    "explanation": "Η βελτιστοποίηση αλγορίθμων εστιάζει στο να γίνουν οι αλγόριθμοι πιο 'έξυπνοι' και λιγότερο απαιτητικοί σε υπολογιστικούς πόρους. Αυτό επιτρέπει την ταχύτερη εκπαίδευση και εκτέλεση των μοντέλων, ακόμα και σε λιγότερο ισχυρό υλικό, μειώνοντας το κόστος."
  },
  {
    "question": "Ποια μελλοντική τάση στοχεύει στη δημιουργία μοντέλων AI που μπορούν να κατανοήσουν και να εξηγήσουν τις αποφάσεις τους;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 108",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "TinyML",
      "B": "Federated Learning",
      "C": "Explainable AI (XAI)",
      "D": "Data-centric AI"
    },
    "explanation": "Η Εξηγήσιμη AI (Explainable AI - XAI) είναι ένας κλάδος που προσπαθεί να λύσει το πρόβλημα των 'μαύρων κουτιών' (black box models). Ο στόχος είναι η ανάπτυξη τεχνικών και μοντέλων που μπορούν να παρέχουν σαφείς εξηγήσεις για το πώς κατέληξαν σε ένα συγκεκριμένο αποτέλεσμα, αυξάνοντας τη διαφάνεια και την εμπιστοσύνη."
  },
  {
    "question": "Τι είναι τα αρχεία CSV;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 94",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Ένας τύπος αρχείου που χρησιμοποιείται για την αποθήκευση δομημένων δεδομένων σε μορφή απλού κειμένου.",
      "B": "Ένας τύπος αρχείου βίντεο υψηλής ανάλυσης.",
      "C": "Ένα λογισμικό για την επεξεργασία εικόνας.",
      "D": "Μια γλώσσα προγραμματισμού για την ανάπτυξη AI."
    },
    "explanation": "Τα αρχεία CSV (Comma-Separated Values) είναι μια πολύ κοινή μορφή για την αποθήκευση και ανταλλαγή δομημένων δεδομένων. Κάθε γραμμή του αρχείου αντιστοιχεί σε μια εγγραφή δεδομένων, και οι τιμές μέσα σε κάθε γραμμή διαχωρίζονται με κόμμα."
  },
  {
    "question": "Γιατί η αποφυγή της υπερεκπαίδευσης (overfitting) είναι σημαντική;",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 99",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Γιατί κάνει την εκπαίδευση του μοντέλου πιο γρήγορη.",
      "B": "Γιατί επιτρέπει στο μοντέλο να απομνημονεύσει τέλεια τα δεδομένα εκπαίδευσης.",
      "C": "Γιατί μειώνει την ανάγκη για καθαρισμό δεδομένων.",
      "D": "Γιατί ένα υπερεκπαιδευμένο μοντέλο αποδίδει άσχημα σε νέα, άγνωστα δεδομένα, καθώς έχει μάθει τον 'θόρυβο' αντί για τα πραγματικά πρότυπα."
    },
    "explanation": "Υπερεκπαίδευση συμβαίνει όταν ένα μοντέλο μαθαίνει τις λεπτομέρειες και τον θόρυβο στα δεδομένα εκπαίδευσης σε τέτοιο βαθμό που δεν μπορεί να γενικεύσει την απόδοσή του σε νέα δεδομένα. Ενώ μπορεί να έχει σχεδόν τέλεια ακρίβεια στα δεδομένα που 'είδε', αποτυγχάνει στην πράξη."
  },
  {
    "question": "Ποιος είναι ο σκοπός της 'Κατευθυντήριας Ανάλυσης' (Prescriptive Analysis);",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 97",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Να περιγράψει τι συνέβη στο παρελθόν.",
      "B": "Να προτείνει συγκεκριμένες δράσεις για την επίτευξη ενός επιθυμητού αποτελέσματος.",
      "C": "Να προβλέψει τι είναι πιθανό να συμβεί στο μέλλον.",
      "D": "Να εξηγήσει γιατί κάτι συνέβη."
    },
    "explanation": "Η Κατευθυντήρια Ανάλυση είναι το πιο προχωρημένο στάδιο. Όχι μόνο προβλέπει τι θα συμβεί, αλλά προχωρά ένα βήμα παραπέρα, προτείνοντας την καλύτερη δυνατή πορεία δράσης για να επηρεάσει τα μελλοντικά αποτελέσματα προς όφελος του οργανισμού. Απαντά στο ερώτημα 'Τι πρέπει να κάνουμε;'"
  }
]
