[
  {
    "question": "Ποια διεθνής οργάνωση έχει υιοθετήσει Καθολική Σύσταση για την Ηθική της Τεχνητής Νοημοσύνης;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "UNESCO",
      "B": "NATO",
      "C": "WHO",
      "D": "FIFA"
    },
    "explanation": "Η UNESCO το 2021 υιοθέτησε τη σύσταση δίνοντας έμφαση στην ισότητα και την κοινωνική συνοχή."
  },
  {
    "question": "Τι αφορά η αρχή της 'ανθρωποκεντρικότητας' (human-centricity) στην Τεχνητή Νοημοσύνη;",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Να σχεδιάζονται ρομπότ που μοιάζουν με ανθρώπους.",
      "B": "Η τεχνολογία να ενισχύει τα ανθρώπινα δικαιώματα και την ευημερία, όχι να τα υποκαθιστά.",
      "C": "Να χρησιμοποιούνται μόνο άνθρωποι για εργασία.",
      "D": "Να απαγορευτεί η χρήση υπολογιστών."
    },
    "explanation": "Η αρχή αυτή επιτάσσει η τεχνολογία να λειτουργεί ως ενισχυτής της ανθρώπινης αυτονομίας και όχι ως αντικαταστάτης της."
  },
  {
    "question": "Τι σημαίνει 'λογοδοσία' (accountability) στο πλαίσιο της ηθικής ΤΝ;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η ικανότητα του συστήματος να μιλάει.",
      "B": "Η καταγραφή των δεδομένων σε λογιστικά φύλλα.",
      "C": "Η σαφήνεια για το ποιος έχει τον έλεγχο και την ευθύνη για τις αποφάσεις ενός αλγορίθμου.",
      "D": "Η ταχύτητα εκτέλεσης εντολών."
    },
    "explanation": "Δεν μπορεί η ευθύνη να αποδίδεται στο 'μαύρο κουτί' της τεχνολογίας, αλλά πρέπει να είναι σαφές ποιος άνθρωπος ή φορέας ευθύνεται."
  },
  {
    "question": "Ποιο είναι το πρόβλημα της 'μεροληψίας εκπαίδευσης' (training bias);",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 275",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Οι αλγόριθμοι κουράζονται κατά την εκπαίδευση.",
      "B": "Τα δεδομένα είναι πολύ μεγάλα για επεξεργασία.",
      "C": "Οι υπολογιστές υπερθερμαίνονται.",
      "D": "Τα μοντέλα μαθαίνουν από ιστορικά δεδομένα που εμπεριέχουν κοινωνικές ανισότητες και στερεότυπα."
    },
    "explanation": "Αν τα δεδομένα του παρελθόντος περιέχουν διακρίσεις (π.χ. κατά των γυναικών), ο αλγόριθμος θα μάθει να τις αναπαράγει."
  },
  {
    "question": "Τι είναι η 'εξηγήσιμη νοημοσύνη' (explainability);",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "5η παράγραφος"
    },
    "choices": {
      "A": "Η ικανότητα του συστήματος να παρέχει κατανοητές εξηγήσεις για τις ενέργειες και αποφάσεις του.",
      "B": "Η ικανότητα του συστήματος να λύνει δύσκολες εξισώσεις.",
      "C": "Η δυνατότητα μετάφρασης σε πολλές γλώσσες.",
      "D": "Η ταχύτητα επεξεργασίας δεδομένων."
    },
    "explanation": "Είναι ηθικά και τεχνικά απαραίτητο να καταλαβαίνουμε *γιατί* ένα σύστημα πήρε μια απόφαση, ειδικά όταν επηρεάζει ζωές."
  },
  {
    "question": "Ποια είναι η κύρια ευρωπαϊκή νομοθετική πρωτοβουλία για την ΤΝ;",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "GDPR II",
      "B": "AI Act (Πράξη για την Τεχνητή Νοημοσύνη)",
      "C": "Digital Markets Act",
      "D": "Cyber Resilience Act"
    },
    "explanation": "Το AI Act είναι το πρώτο παγκοσμίως νομικά δεσμευτικό πλαίσιο που ρυθμίζει την ΤΝ βάσει κινδύνου."
  },
  {
    "question": "Σε πόσες κατηγορίες κινδύνου κατατάσσει τα συστήματα ΤΝ το AI Act;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Δύο",
      "B": "Τρεις",
      "C": "Τέσσερις",
      "D": "Πέντε"
    },
    "explanation": "Οι κατηγορίες είναι: Απαγορευμένα, Υψηλού κινδύνου, Περιορισμένου κινδύνου και Ελάχιστου κινδύνου."
  },
  {
    "question": "Τι προβλέπεται για τα συστήματα ΤΝ 'υψηλού κινδύνου' στο AI Act;",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "1η παράγραφος (κάτω από την εικόνα)"
    },
    "choices": {
      "A": "Πλήρης απαγόρευση.",
      "B": "Κανένας έλεγχος.",
      "C": "Εθελοντική συμμόρφωση.",
      "D": "Υποχρεώσεις αξιολόγησης, διαφάνειας, ανθρώπινης εποπτείας και τεκμηρίωσης."
    },
    "explanation": "Λόγω της κρισιμότητάς τους (π.χ. υγεία, δικαιοσύνη), αυτά τα συστήματα υπόκεινται σε αυστηρούς κανόνες πριν κυκλοφορήσουν."
  },
  {
    "question": "Ποια αρχή αναφέρεται στην αποφυγή βλάβης (non-maleficence);",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "6η παράγραφος"
    },
    "choices": {
      "A": "Η αποτροπή καταστάσεων όπου η ΤΝ μπορεί να προκαλέσει υλική, ψυχολογική ή θεσμική ζημιά.",
      "B": "Η απαγόρευση χρήσης ηλεκτρισμού.",
      "C": "Η προστασία των πνευματικών δικαιωμάτων.",
      "D": "Η αύξηση της κερδοφορίας."
    },
    "explanation": "Αφορά την προστασία από κακόβουλη ή αμελή χρήση της τεχνολογίας, όπως στην επιτήρηση ή χειραγώγηση."
  },
  {
    "question": "Τι είναι τα 'Sandbox' που αναφέρονται στο AI Act;",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "1η παράγραφος (κάτω από την εικόνα)"
    },
    "choices": {
      "A": "Παιχνίδια στην άμμο.",
      "B": "Ρυθμιστικά πειραματικά περιβάλλοντα για την ασφαλή δοκιμή καινοτόμων εγχειρημάτων.",
      "C": "Κουτιά αποθήκευσης δεδομένων.",
      "D": "Φίλτρα spam."
    },
    "explanation": "Επιτρέπουν την ανάπτυξη και δοκιμή νέων τεχνολογιών σε ελεγχόμενο περιβάλλον πριν την ευρεία διάθεση."
  },
  {
    "question": "Ποια είναι μια από τις πέντε αρχές του OECD για την ΤΝ;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Μέγιστο κέρδος.",
      "B": "Ταχύτητα.",
      "C": "Ανθρώπινη εποπτεία.",
      "D": "Αυτοματοποίηση όλων."
    },
    "explanation": "Ο OECD τονίζει την ανάγκη να παραμένει ο άνθρωπος 'στο κύκλωμα' (human-in-the-loop) για έλεγχο."
  },
  {
    "question": "Τι είδους σύστημα θεωρείται 'Απαγορευμένο' σύμφωνα με το AI Act;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Ένα chatbot.",
      "B": "Ένα φίλτρο spam.",
      "C": "Ένα σύστημα πλοήγησης.",
      "D": "Σύστημα κοινωνικής βαθμολόγησης (social scoring) ή μαζικής επιτήρησης χωρίς έλεγχο."
    },
    "explanation": "Τέτοια συστήματα θεωρούνται απαράδεκτα για τις ευρωπαϊκές αξίες και τα θεμελιώδη δικαιώματα."
  },
  {
    "question": "Ποιο πρόγραμμα έχει αναπτύξει το IEEE για την ηθική στην ΤΝ;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Ethically Aligned Design",
      "B": "Green AI",
      "C": "Tech for Good",
      "D": "Smart Future"
    },
    "explanation": "Προωθεί την ενσωμάτωση ηθικών αξιών από τη φάση του σχεδιασμού ενός συστήματος."
  },
  {
    "question": "Ποια είναι η σημασία της 'διαφάνειας' (transparency) στην ΤΝ;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 282",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Να είναι αόρατο το ρομπότ.",
      "B": "Να υπάρχουν σαφείς πληροφορίες για το πώς λειτουργεί ένα σύστημα, ώστε να υπάρχει έλεγχος.",
      "C": "Να είναι δωρεάν το λογισμικό.",
      "D": "Να μην έχει κωδικούς πρόσβασης."
    },
    "explanation": "Χωρίς διαφάνεια, δεν μπορεί να υπάρξει εμπιστοσύνη ή απόδοση ευθυνών (λογοδοσία)."
  },
  {
    "question": "Τι είναι η 'μεροληψία' (bias) στους αλγορίθμους;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 275",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Ένα τεχνικό λάθος στον κώδικα.",
      "B": "Η ταχύτητα του επεξεργαστή.",
      "C": "Η αναπαραγωγή ή ενίσχυση κοινωνικών προκαταλήψεων και ανισοτήτων από το σύστημα.",
      "D": "Η αύξηση της μνήμης RAM."
    },
    "explanation": "Δεν είναι 'κακή πρόθεση' της μηχανής, αλλά αποτέλεσμα στρεβλών δεδομένων ή σχεδιασμού."
  },
  {
    "question": "Ποιο παράδειγμα συστήματος αναφέρεται ως 'Περιορισμένου κινδύνου' στο AI Act;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Κοινωνική βαθμολόγηση.",
      "B": "Ιατρικό ρομπότ.",
      "C": "Αυτόνομο όπλο.",
      "D": "Chatbots που απαιτούν απλώς ενημέρωση του χρήστη ότι μιλάει με μηχανή."
    },
    "explanation": "Εδώ ο κίνδυνος είναι η παραπλάνηση, γι' αυτό απαιτείται διαφάνεια (να ξέρεις ότι μιλάς με μποτ)."
  },
  {
    "question": "Τι σημαίνει 'ευθύνη εκ προθέσεως' (intentional responsibility);",
    "answer": "A",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 282",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η αντίληψη ότι κάποιος φταίει μόνο αν είχε σκοπό να βλάψει.",
      "B": "Η ευθύνη για ατύχημα.",
      "C": "Η ευθύνη του προγραμματιστή.",
      "D": "Η νομική ευθύνη των ρομπότ."
    },
    "explanation": "Το κείμενο εξηγεί ότι αυτή η λογική δεν αρκεί στην ΤΝ, καθώς ζημιά μπορεί να γίνει και χωρίς κακή πρόθεση."
  },
  {
    "question": "Ποιος είναι ο ρόλος των 'εσωτερικών επιτροπών ηθικής' στις επιχειρήσεις;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Να αυξάνουν τις πωλήσεις.",
      "B": "Να διασφαλίζουν την τήρηση Κωδίκων Δεοντολογίας και τη συμμόρφωση με ηθικές αρχές.",
      "C": "Να απολύουν προσωπικό.",
      "D": "Να διοργανώνουν πάρτι."
    },
    "explanation": "Πολλές εταιρείες υιοθετούν αυτορρύθμιση για να προλάβουν κινδύνους και να χτίσουν εμπιστοσύνη."
  },
  {
    "question": "Ποιο είναι ένα παράδειγμα συστήματος 'Ελάχιστου κινδύνου' στο AI Act;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Αναγνώριση προσώπου.",
      "B": "Αξιολόγηση δανείων.",
      "C": "Φίλτρα spam.",
      "D": "Χειρουργικό ρομπότ."
    },
    "explanation": "Αυτά τα συστήματα δεν απαιτούν ειδικούς κανονισμούς καθώς δεν απειλούν δικαιώματα."
  },
  {
    "question": "Πώς η έλλειψη διαφάνειας επηρεάζει τη λήψη αποφάσεων;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "5η παράγραφος"
    },
    "choices": {
      "A": "Την κάνει πιο γρήγορη.",
      "B": "Την κάνει πιο φθηνή.",
      "C": "Την κάνει πιο εύκολη.",
      "D": "Ισοδυναμεί με αποξένωση από τη διαδικασία, ειδικά σε κρίσιμες αποφάσεις για ανθρώπινες ζωές."
    },
    "explanation": "Αν δεν ξέρεις πώς βγήκε η απόφαση, δεν μπορείς να την κρίνεις, να την αμφισβητήσεις ή να τη διορθώσεις."
  },
  {
    "question": "Ποια ήταν η 'Καθολική Σύσταση' της UNESCO για την ΤΝ;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Μια σύσταση που δίνει έμφαση στην ισότητα, τη διαφορετικότητα και την κοινωνική συνοχή.",
      "B": "Μια σύσταση για περισσότερα ρομπότ.",
      "C": "Μια σύσταση για απαγόρευση της ΤΝ.",
      "D": "Μια σύσταση για χρήση ΤΝ στον πόλεμο."
    },
    "explanation": "Στόχος είναι η ΤΝ να ωφελεί όλη την ανθρωπότητα, όχι λίγους."
  },
  {
    "question": "Τι είναι τα 'εργαλεία εκτίμησης επιπτώσεων' (impact assessment tools);",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Εργαλεία για επισκευές.",
      "B": "Εργαλεία που χρησιμοποιούν οι επιχειρήσεις για να προβλέψουν και να αξιολογήσουν τις συνέπειες χρήσης συστημάτων ΤΝ.",
      "C": "Εργαλεία για μείωση φόρων.",
      "D": "Εργαλεία για διαφήμιση."
    },
    "explanation": "Βοηθούν τις εταιρείες να εντοπίσουν ηθικούς κινδύνους πριν αυτοί προκύψουν."
  },
  {
    "question": "Στη μελέτη περίπτωσης (σελ. 285), ποιο ήταν το πρόβλημα με το σύστημα αξιολόγησης βιογραφικών;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 285",
      "paragraph": "1η παράγραφος (εισαγωγή)"
    },
    "choices": {
      "A": "Ήταν πολύ αργό.",
      "B": "Κόστιζε ακριβά.",
      "C": "Εμφάνισε μεροληψία (bias) κατά τη δοκιμαστική λειτουργία.",
      "D": "Δεν δούλευε καθόλου."
    },
    "explanation": "Το σύστημα, μαθαίνοντας από παλιά δεδομένα, πιθανότατα αναπαρήγαγε διακρίσεις."
  },
  {
    "question": "Τι σημαίνει η αρχή της 'Δικαιοσύνης' (Fairness) στην ΤΝ;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Να δικάζουν τα ρομπότ.",
      "B": "Να είναι όλα ίδια.",
      "C": "Να μην υπάρχουν νόμοι.",
      "D": "Ίση πρόσβαση σε ευκαιρίες, αποτροπή διακρίσεων και εξισορρόπηση ανισοτήτων."
    },
    "explanation": "Σημαίνει ότι ο αλγόριθμος δεν πρέπει να ευνοεί ή να αδικεί κανέναν λόγω φυλής, φύλου κ.λπ."
  },
  {
    "question": "Ποιο είναι το ρίσκο της 'ΤΝ που αγνοεί την ηθική' για μια επιχείρηση;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 285",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Δυσφήμιση, νομικοί κίνδυνοι και απώλεια εμπιστοσύνης.",
      "B": "Αύξηση κερδών.",
      "C": "Βελτίωση φήμης.",
      "D": "Καμία επίπτωση."
    },
    "explanation": "Η ανηθικότητα κοστίζει ακριβά σε φήμη και πρόστιμα."
  },
  {
    "question": "Τι είναι η 'Συμμετοχικότητα' στην ανάπτυξη ηθικής ΤΝ;",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 274",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Να συμμετέχουν μόνο προγραμματιστές.",
      "B": "Να συμμετέχουν όλα τα ενδιαφερόμενα μέρη (πολίτες, ερευνητές, νομοθέτες) στον σχεδιασμό και την εποπτεία.",
      "C": "Να συμμετέχουν μόνο εταιρείες.",
      "D": "Να μην συμμετέχει κανείς."
    },
    "explanation": "Η ηθική δεν είναι δουλειά μόνο των ειδικών, αλλά ολόκληρης της κοινωνίας."
  },
  {
    "question": "Ποιο είναι ένα παράδειγμα 'εσκεμμένης βλάβης' μέσω ΤΝ;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 274",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Ένα λάθος στον κώδικα.",
      "B": "Η αργή απόκριση.",
      "C": "Η στοχοποίηση, η ψυχολογική χειραγώγηση ή η ανεξέλεγκτη επιτήρηση.",
      "D": "Η κατανάλωση ρεύματος."
    },
    "explanation": "Εδώ η τεχνολογία χρησιμοποιείται ως όπλο κατά των ανθρώπων."
  },
  {
    "question": "Τι προβλέπει το AI Act για την 'κοινωνική βαθμολόγηση' (social scoring);",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Την επιτρέπει με άδεια.",
      "B": "Την επιτρέπει μόνο σε σχολεία.",
      "C": "Την ενθαρρύνει.",
      "D": "Την κατατάσσει στα 'Απαγορευμένα συστήματα'."
    },
    "explanation": "Θεωρείται δυστοπική πρακτική ασυμβίβαστη με την ελευθερία."
  },
  {
    "question": "Ποια είναι η σχέση 'Ευθύνης' και 'Καινοτομίας' σύμφωνα με το κείμενο;",
    "answer": "A",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 282",
      "paragraph": "5η παράγραφος"
    },
    "choices": {
      "A": "Η ευθύνη δεν είναι εμπόδιο, αλλά θεμέλιο αξιόπιστης τεχνολογίας και κοινωνικής αποδοχής.",
      "B": "Η ευθύνη σκοτώνει την καινοτομία.",
      "C": "Η καινοτομία δεν χρειάζεται ευθύνη.",
      "D": "Είναι αντίθετες έννοιες."
    },
    "explanation": "Μόνο αν ο κόσμος εμπιστεύεται την τεχνολογία θα την υιοθετήσει μαζικά."
  },
  {
    "question": "Τι είναι τα 'συστήματα υψηλού κινδύνου' (high-risk) κατά το AI Act;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Video games.",
      "B": "Συστήματα σε κρίσιμους τομείς όπως εκπαίδευση, υγεία, δικαιοσύνη και χρηματοδότηση.",
      "C": "Social media apps.",
      "D": "Smartwatches."
    },
    "explanation": "Ένα λάθος εδώ μπορεί να καταστρέψει ζωές, γι' αυτό απαιτούνται αυστηρές προδιαγραφές."
  },
  {
    "question": "Ποια είναι η βασική αιτία της 'Μη εξηγήσιμης' ΤΝ (Black Box);",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "3η παράγραφος (υπονοείται)"
    },
    "choices": {
      "A": "Είναι μυστικό.",
      "B": "Είναι παράνομο.",
      "C": "Η πολυπλοκότητα των μοντέλων (π.χ. νευρωνικά δίκτυα) που καθιστά τη λειτουργία τους αδιαφανή.",
      "D": "Η έλλειψη οθόνης."
    },
    "explanation": "Τα βαθιά δίκτυα κάνουν εκατομμύρια υπολογισμούς που είναι αδύνατον να παρακολουθήσει ανθρώπινος νους."
  },
  {
    "question": "Τι επιδιώκει η 'G7 και G20' σχετικά με την ΤΝ;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Να σταματήσουν την έρευνα.",
      "B": "Να φορολογήσουν τα ρομπότ.",
      "C": "Να φτιάξουν δικό τους στρατό.",
      "D": "Την παγκόσμια τεχνολογική συνεργασία, τη διαλειτουργικότητα και την προστασία αξιών."
    },
    "explanation": "Η ΤΝ είναι παγκόσμιο φαινόμενο και απαιτεί διεθνή συντονισμό."
  },
  {
    "question": "Πώς η 'λογική της ηθικής απόδοσης ευθύνης' εφαρμόζεται σε αυτόνομα συστήματα;",
    "answer": "A",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Πρέπει να είναι σαφές ποιος απαντά σε περιπτώσεις σφαλμάτων, ακόμη και αν το σύστημα λειτουργεί αυτόνομα.",
      "B": "Φταίει το ρομπότ.",
      "C": "Δεν φταίει κανείς.",
      "D": "Φταίει ο χρήστης."
    },
    "explanation": "Η αυτονομία δεν σημαίνει ανευθυνότητα. Κάποιος άνθρωπος πρέπει πάντα να είναι υπόλογος."
  },
  {
    "question": "Τι είναι η 'Risk-based approach' του AI Act;",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Όλα τα συστήματα είναι επικίνδυνα.",
      "B": "Η ρύθμιση των συστημάτων ανάλογα με το επίπεδο κινδύνου που παρουσιάζουν (όσο μεγαλύτερος ο κίνδυνος, τόσο αυστηρότεροι οι κανόνες).",
      "C": "Κανένας κανόνας.",
      "D": "Απαγόρευση όλων."
    },
    "explanation": "Είναι μια αναλογική προσέγγιση: δεν χρειάζεται η ίδια αυστηρότητα για ένα παιχνίδι και για ένα χειρουργικό εργαλείο."
  },
  {
    "question": "Ποιο είναι το πρόβλημα με τα δεδομένα που περιέχουν 'κοινωνικές ανισότητες';",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Είναι δύσκολο να διαβαστούν.",
      "B": "Πιάνουν χώρο.",
      "C": "Εκπαιδεύουν συστήματα που αναπαράγουν ή ενισχύουν προκαταλήψεις (bias).",
      "D": "Είναι παλιά."
    },
    "explanation": "Garbage in, garbage out. Αν τα δεδομένα είναι άδικα, και η απόφαση θα είναι άδικη."
  },
  {
    "question": "Τι είναι η 'Ανθρώπινη Εποπτεία' (Human Oversight) στο AI Act;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "1η παράγραφος (κάτω από εικόνα)"
    },
    "choices": {
      "A": "Να κοιτάς την οθόνη.",
      "B": "Να βλέπεις βίντεο.",
      "C": "Να έχεις κάμερες.",
      "D": "Υποχρέωση για συστήματα υψηλού κινδύνου να επιβλέπονται από ανθρώπους."
    },
    "explanation": "Ο άνθρωπος πρέπει να έχει το 'τελευταίο λόγο' και τη δυνατότητα να παρέμβει ή να σταματήσει το σύστημα."
  },
  {
    "question": "Ποιος οργανισμός προτείνει 'ένταξη, ασφάλεια, διαφάνεια, λογοδοσία και ανθρώπινη εποπτεία' ως αρχές;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 284",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "OECD (ΟΟΣΑ)",
      "B": "FIFA",
      "C": "NBA",
      "D": "NASA"
    },
    "explanation": "Ο ΟΟΣΑ έχει θέσει ένα ισχυρό πλαίσιο αρχών που υιοθετήθηκε από πολλές χώρες."
  },
  {
    "question": "Τι πρέπει να κάνουν οι οργανισμοί για να εξαλείψουν τις προκαταλήψεις;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 273",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Να αγνοήσουν το πρόβλημα.",
      "B": "Να εφαρμόζουν δίκαιη σχεδίαση και συνεπή αξιολόγηση των αποτελεσμάτων των συστημάτων τους.",
      "C": "Να σταματήσουν να χρησιμοποιούν δεδομένα.",
      "D": "Να χρησιμοποιούν μόνο άντρες προγραμματιστές."
    },
    "explanation": "Χρειάζεται ενεργητική προσπάθεια και συνεχή έλεγχο για να διασφαλιστεί το Fairness."
  },
  {
    "question": "Ποια είναι η σχέση του AI Act με την καινοτομία;",
    "answer": "C",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 285",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Την απαγορεύει.",
      "B": "Την αγνοεί.",
      "C": "Στοχεύει να λειτουργήσει ως υποδομή εμπιστοσύνης πάνω στην οποία θα χτιστεί ωφέλιμη ΤΝ, όχι ως τροχοπέδη.",
      "D": "Επιβάλλει μόνο φόρους."
    },
    "explanation": "Η σωστή ρύθμιση δημιουργεί ασφάλεια δικαίου που ενθαρρύνει τις επενδύσεις."
  },
  {
    "question": "Τι απαιτείται για τα 'chatbots' σύμφωνα με το AI Act;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 283",
      "paragraph": "2η παράγραφος (λίστα)"
    },
    "choices": {
      "A": "Να είναι έξυπνα.",
      "B": "Να είναι αστεία.",
      "C": "Να μην κάνουν λάθη.",
      "D": "Ενημέρωση του χρήστη ότι επικοινωνεί με μηχανή (διαφάνεια)."
    },
    "explanation": "Είναι θέμα εντιμότητας και προστασίας του καταναλωτή από παραπλάνηση."
  }
]
