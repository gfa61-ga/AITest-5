[
    {
        "question": "Ποιος είναι ο βασικός στόχος της Επεξεργασίας Φυσικής Γλώσσας (NLP);",
        "answer": "A",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 219",
            "paragraph": "1η παράγραφος (ενότητα 7.3)"
        },
        "choices": {
            "A": "Η μετατροπή της ανθρώπινης γλώσσας σε αριθμούς για κατανόηση από μηχανές",
            "B": "Η αποκλειστική καταγραφή της ανθρώπινης ομιλίας χωρίς περαιτέρω επεξεργασία",
            "C": "Η δημιουργία νέων γλωσσών προγραμματισμού για υπολογιστές",
            "D": "Η ανάλυση της δομής των μαθηματικών εξισώσεων σε κείμενα"
        },
        "explanation": "Σύμφωνα με την ενότητα 7.3, για να επεξεργαστεί ένα σύστημα φυσική γλώσσα, πρέπει να μετατρέψει τις λέξεις σε μορφή που κατανοεί, δηλαδή σε αριθμούς (διανυσματοποίηση)."
    },
    {
        "question": "Ποια διαδικασία προεπεξεργασίας κειμένου μετατρέπει χαρακτήρες σε πεζά και αφαιρεί σημεία στίξης;",
        "answer": "B",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (ενότητα 7.2)"
        },
        "choices": {
            "A": "Διαχωρισμός Λέξεων",
            "B": "Κανονικοποίηση Κειμένου",
            "C": "Απαλοιφή Καταλήξεων",
            "D": "Αναγνώριση Ονομαστικών Οντοτήτων"
        },
        "explanation": "Η Κανονικοποίηση Κειμένου (Text Normalization) περιλαμβάνει τη μετατροπή χαρακτήρων σε πεζά και την αφαίρεση σημείων στίξης για μείωση της πολυπλοκότητας."
    },
    {
        "question": "Τι επιτυγχάνει η διαδικασία του Tokenization;",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (ενότητα 7.2)"
        },
        "choices": {
            "A": "Τη μετατροπή του κειμένου σε διανύσματα",
            "B": "Την αφαίρεση των συχνών λέξεων όπως 'και'",
            "C": "Τον διαχωρισμό της πρότασης σε λέξεις ή φράσεις",
            "D": "Τη διόρθωση ορθογραφικών λαθών στο κείμενο"
        },
        "explanation": "Το Tokenization (Διαχωρισμός Λέξεων) είναι η διαδικασία διαχωρισμού μιας πρότασης σε επιμέρους μονάδες, όπως λέξεις ή φράσεις (tokens)."
    },
    {
        "question": "Ποια είναι η διαφορά μεταξύ Stemming και Lemmatization;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (ενότητα 7.2)"
        },
        "choices": {
            "A": "Το Stemming επιστρέφει τη γραμματική μορφή, ενώ το Lemmatization τη ρίζα",
            "B": "Και τα δύο κάνουν ακριβώς την ίδια διαδικασία χωρίς διαφορά",
            "C": "Το Lemmatization αφαιρεί τα σημεία στίξης, ενώ το Stemming όχι",
            "D": "Το Stemming κρατά τη ρίζα, ενώ το Lemmatization τη γραμματική βασική μορφή"
        },
        "explanation": "Το Stemming διατηρεί μόνο τη ρίζα της λέξης, ενώ η Λημματοποίηση (Lemmatization) επιστρέφει τη γραμματική βασική μορφή της λέξης."
    },
    {
        "question": "Τι περιλαμβάνει η αφαίρεση Stopwords;",
        "answer": "A",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (ενότητα 7.2)"
        },
        "choices": {
            "A": "Την απομάκρυνση κοινών λέξεων χωρίς ιδιαίτερη σημασία",
            "B": "Την αφαίρεση όλων των ρημάτων από το κείμενο",
            "C": "Την εξάλειψη των σπάνιων λέξεων από το κείμενο",
            "D": "Τη διαγραφή των ονομάτων από το κείμενο"
        },
        "explanation": "Η Αφαίρεση Λέξεων Κοινής Χρήσης (Stopword Removal) αφορά την απομάκρυνση λέξεων όπως «ο», «η», «και», που δεν προσθέτουν ιδιαίτερη σημασία."
    },
    {
        "question": "Ποια μέθοδος διανυσματοποίησης δημιουργεί έναν πίνακα εμφάνισης λέξεων;",
        "answer": "B",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 219",
            "paragraph": "2η παράγραφος (ενότητα 7.3)"
        },
        "choices": {
            "A": "Word Embeddings",
            "B": "Bag-of-Words",
            "C": "Transformers",
            "D": "Spelling Correction"
        },
        "explanation": "Η μέθοδος Bag-of-Words (Σάκος Λέξεων) μετατρέπει κάθε κείμενο σε έναν πίνακα όπου καταγράφεται πόσες φορές εμφανίζεται κάθε λέξη του λεξικού."
    },
    {
        "question": "Τι λαμβάνει υπόψη η μέθοδος TF-IDF;",
        "answer": "C",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 219",
            "paragraph": "3η παράγραφος (ενότητα 7.3)"
        },
        "choices": {
            "A": "Μόνο τη συχνότητα εμφάνισης της λέξης στο συγκεκριμένο έγγραφο",
            "B": "Τη γραμματική συντακτική θέση της λέξης στην πρόταση",
            "C": "Τη συχνότητα της λέξης στο κείμενο σε σχέση με τη συχνότητα σε όλα τα κείμενα",
            "D": "Την ορθογραφική ορθότητα της λέξης στο λεξικό"
        },
        "explanation": "Η TF-IDF λαμβάνει υπόψη πόσο συχνά εμφανίζεται μια λέξη σε ένα κείμενο σε σχέση με το πόσο συχνά εμφανίζεται σε όλα τα κείμενα, αναδεικνύοντας σπάνιες αλλά σημαντικές λέξεις."
    },
    {
        "question": "Ποιο είναι το βασικό μειονέκτημα των μεθόδων Bag-of-Words και TF-IDF;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "1η παράγραφος"
        },
        "choices": {
            "A": "Απαιτούν εξαιρετικά μεγάλους υπολογιστικούς πόρους για μικρά κείμενα",
            "B": "Δεν μπορούν να επεξεργαστούν κείμενα στην αγγλική γλώσσα",
            "C": "Δημιουργούν λανθασμένα ορθογραφικά αποτελέσματα",
            "D": "Αγνοούν τη σημασιολογική σχέση μεταξύ των λέξεων"
        },
        "explanation": "Οι τεχνικές Bag-of-Words και TF-IDF αγνοούν τη σημασιολογική σχέση μεταξύ των λέξεων, όπως για παράδειγμα τη συγγένεια των λέξεων «αυτοκίνητο» και «όχημα»."
    },
    {
        "question": "Τι επιτυγχάνει το μοντέλο Word2Vec;",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (Word2Vec)"
        },
        "choices": {
            "A": "Τοποθετεί λέξεις με παρόμοιο νόημα κοντά σε έναν πολυδιάστατο χώρο",
            "B": "Μετατρέπει τις λέξεις σε εικόνες για οπτική επεξεργασία",
            "C": "Αφαιρεί όλες τις λέξεις που δεν είναι ουσιαστικά",
            "D": "Δημιουργεί νέες λέξεις που δεν υπάρχουν στο λεξικό"
        },
        "explanation": "Το Word2Vec εκπαιδεύεται ώστε να τοποθετεί λέξεις με παρόμοιο νόημα κοντά μεταξύ τους σε έναν πολυδιάστατο χώρο (π.χ. «βασιλιάς» και «βασίλισσα»)."
    },
    {
        "question": "Ποιο μοντέλο embedding είναι ιδιαίτερα χρήσιμο για γλώσσες με πλούσια μορφολογία όπως τα ελληνικά;",
        "answer": "B",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (FastText)"
        },
        "choices": {
            "A": "GloVe",
            "B": "FastText",
            "C": "Word2Vec",
            "D": "Bag-of-Words"
        },
        "explanation": "Το FastText επεκτείνει το Word2Vec και λαμβάνει υπόψη τα υποσυστήματα των λέξεων (προθέματα, καταλήξεις), κάτι χρήσιμο για μορφολογικά πλούσιες γλώσσες."
    },
    {
        "question": "Τι χαρακτηρίζει τα Contextualized Embeddings (π.χ. BERT);",
        "answer": "C",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (Contextualized Embeddings)"
        },
        "choices": {
            "A": "Αποδίδουν το ίδιο διάνυσμα σε μια λέξη ανεξαρτήτως του πλαισίου της",
            "B": "Χρησιμοποιούν μόνο τη συχνότητα εμφάνισης των λέξεων",
            "C": "Η ίδια λέξη έχει διαφορετικό διάνυσμα ανάλογα με τα συμφραζόμενα",
            "D": "Βασίζονται αποκλειστικά σε λεξικά ορισμών χωρίς αριθμητική μετατροπή"
        },
        "explanation": "Στα Contextualized Embeddings, η ίδια λέξη λαμβάνει διαφορετικό διάνυσμα ανάλογα με το συμφραζόμενο, σε αντίθεση με τις στατικές μεθόδους."
    },
    {
        "question": "Ποιος είναι ο στόχος της Ανάλυσης Συναισθήματος;",
        "answer": "D",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 221",
            "paragraph": "1η παράγραφος (ενότητα 7.4)"
        },
        "choices": {
            "A": "Η διόρθωση των συντακτικών λαθών σε ένα κείμενο",
            "B": "Η μετάφραση του κειμένου σε άλλη γλώσσα",
            "C": "Η δημιουργία περίληψης του κειμένου",
            "D": "Ο εντοπισμός και κατηγοριοποίηση του συναισθήματος ενός κειμένου"
        },
        "explanation": "Η Ανάλυση Συναισθήματος (Sentiment Analysis) στοχεύει στον εντοπισμό και την κατηγοριοποίηση του συναισθήματος (θετικό, αρνητικό, ουδέτερο) πίσω από ένα κείμενο."
    },
    {
        "question": "Πού χρησιμοποιείται ευρέως η Ανάλυση Συναισθήματος;",
        "answer": "A",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 221",
            "paragraph": "1η παράγραφος (ενότητα 7.4)"
        },
        "choices": {
            "A": "Στα μέσα κοινωνικής δικτύωσης και τις αναλύσεις εμπειρίας πελάτη",
            "B": "Στην αυτόματη οδήγηση οχημάτων",
            "C": "Στον σχεδιασμό ιστοσελίδων",
            "D": "Στην κατασκευή ρομποτικών βραχιόνων"
        },
        "explanation": "Η ανάλυση συναισθήματος χρησιμοποιείται ευρέως στα μέσα κοινωνικής δικτύωσης, στις αναλύσεις εμπειρίας πελάτη, σε ηλεκτρονικά καταστήματα και δημοσκοπήσεις."
    },
    {
        "question": "Ποιο από τα παρακάτω είναι παράδειγμα Ταξινόμησης Κειμένου;",
        "answer": "B",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "1η παράγραφος (Ταξινόμηση Κειμένου)"
        },
        "choices": {
            "A": "Η εύρεση της ρίζας μιας λέξης",
            "B": "Ο χαρακτηρισμός ενός email ως «ανεπιθύμητο» ή «έγκυρο»",
            "C": "Η μετατροπή κειμένου σε ομιλία",
            "D": "Η αναγνώριση προσώπων σε μια φωτογραφία"
        },
        "explanation": "Η Ταξινόμηση Κειμένου περιλαμβάνει την κατάταξη ενός εγγράφου σε κατηγορίες, όπως ο χαρακτηρισμός ενός email ως spam (ανεπιθύμητο) ή ham (έγκυρο)."
    },
    {
        "question": "Τι εντοπίζει η Αναγνώριση Ονομαστικών Οντοτήτων (NER);",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "2η παράγραφος (NER)"
        },
        "choices": {
            "A": "Τα ορθογραφικά λάθη σε μια πρόταση",
            "B": "Το γενικό συναίσθημα του κειμένου",
            "C": "Λέξεις που αντιπροσωπεύουν οντότητες όπως πρόσωπα και τοποθεσίες",
            "D": "Τις πιο συχνές λέξεις σε ένα κείμενο"
        },
        "explanation": "Η Αναγνώριση Ονομαστικών Οντοτήτων (NER) στοχεύει στον εντοπισμό λέξεων ή φράσεων που αντιπροσωπεύουν οντότητες, όπως ονόματα προσώπων, τοποθεσιών, οργανισμών κ.λπ."
    },
    {
        "question": "Ποια κατηγορία οντοτήτων περιλαμβάνει το παράδειγμα «Ευρωπαϊκή Ένωση»;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "Λίστα (NER)"
        },
        "choices": {
            "A": "Ονόματα προσώπων",
            "B": "Ημερομηνίες και ποσά",
            "C": "Ονόματα τοποθεσιών",
            "D": "Οργανισμοί"
        },
        "explanation": "Στο κείμενο αναφέρεται ότι η «Ευρωπαϊκή Ένωση» και η «Google» αποτελούν παραδείγματα της κατηγορίας «Οργανισμοί» στην Αναγνώριση Ονομαστικών Οντοτήτων."
    },
    {
        "question": "Ποιο είναι το βασικό χαρακτηριστικό των Αναδρομικών Νευρωνικών Δικτύων (RNN);",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.1)"
        },
        "choices": {
            "A": "Διατηρούν εσωτερική μνήμη για την επεξεργασία ακολουθιών",
            "B": "Επεξεργάζονται όλες τις λέξεις ταυτόχρονα παράλληλα",
            "C": "Δεν χρησιμοποιούν καθόλου δεδομένα εκπαίδευσης",
            "D": "Είναι κατάλληλα μόνο για επεξεργασία εικόνας"
        },
        "explanation": "Τα RNN διατηρούν εσωτερική μνήμη, η οποία τους επιτρέπει να επηρεάζουν την επεξεργασία τρέχοντων λέξεων βάσει προηγούμενων, κατάλληλα για δεδομένα ακολουθίας."
    },
    {
        "question": "Ποιο πρόβλημα αντιμετωπίζουν τα απλά RNN σε μεγάλες ακολουθίες;",
        "answer": "B",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "2η παράγραφος (7.5.1)"
        },
        "choices": {
            "A": "Το πρόβλημα της υπερβολικής ταχύτητας επεξεργασίας",
            "B": "Το πρόβλημα της εξαφάνισης της κλίσης (vanishing gradient)",
            "C": "Το πρόβλημα της υπερβολικής μνήμης",
            "D": "Το πρόβλημα της μη αναγνώρισης αριθμών"
        },
        "explanation": "Τα RNN δυσκολεύονται να διατηρήσουν πληροφορίες από μακρινά σημεία στο κείμενο, ένα πρόβλημα γνωστό ως vanishing gradient problem."
    },
    {
        "question": "Πώς επιλύουν τα LSTM τα προβλήματα μνήμης των RNN;",
        "answer": "C",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.2)"
        },
        "choices": {
            "A": "Αφαιρώντας τελείως τη μνήμη από το δίκτυο",
            "B": "Χρησιμοποιώντας μόνο μία κατεύθυνση ανάγνωσης",
            "C": "Χρησιμοποιώντας μηχανισμούς ελέγχου (πύλες – gates)",
            "D": "Αυξάνοντας απλώς τον αριθμό των νευρώνων τυχαία"
        },
        "explanation": "Τα LSTM χρησιμοποιούν μηχανισμούς ελέγχου (πύλες/gates) για να αποφασίζουν ποιες πληροφορίες θα διατηρηθούν και ποιες θα ξεχαστούν."
    },
    {
        "question": "Ποια καινοτομία εισήγαγαν οι Μετασχηματιστές (Transformers);",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.3)"
        },
        "choices": {
            "A": "Την επεξεργασία λέξεων αποκλειστικά μία προς μία",
            "B": "Την κατάργηση των νευρωνικών δικτύων",
            "C": "Τη χρήση αποκλειστικά στατικών λεξικών",
            "D": "Τον μηχανισμό αυτοπροσοχής (self-attention)"
        },
        "explanation": "Οι Transformers βασίζονται στην αυτοπροσοχή (self-attention), που επιτρέπει στο μοντέλο να εντοπίζει σημαντικές λέξεις ανεξαρτήτως της θέσης τους."
    },
    {
        "question": "Ποιο είναι ένα βασικό πλεονέκτημα των Transformers έναντι των RNN/LSTM;",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "1η παράγραφος"
        },
        "choices": {
            "A": "Υποστηρίζουν την παράλληλη επεξεργασία δεδομένων",
            "B": "Απαιτούν λιγότερα δεδομένα για εκπαίδευση",
            "C": "Είναι πιο αργοί αλλά πιο ακριβείς",
            "D": "Λειτουργούν μόνο με μικρές προτάσεις"
        },
        "explanation": "Οι μετασχηματιστές υποστηρίζουν παράλληλη επεξεργασία και υπερτερούν στην ταχύτητα και την απόδοση σε σύγκριση με τα RNN/LSTM."
    },
    {
        "question": "Τι σημαίνει το ακρωνύμιο BERT;",
        "answer": "B",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "Λίστα (7.5.4)"
        },
        "choices": {
            "A": "Binary Encoder Representations from Text",
            "B": "Bidirectional Encoder Representations from Transformers",
            "C": "Basic English Recognition Transformer",
            "D": "Big Entity Recognition Technology"
        },
        "explanation": "Το BERT σημαίνει Bidirectional Encoder Representations from Transformers, όπως αναφέρεται στην ενότητα 7.5.4."
    },
    {
        "question": "Ποιο χαρακτηριστικό κάνει το BERT ιδανικό για κατανόηση κειμένου;",
        "answer": "C",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "Λίστα (7.5.4)"
        },
        "choices": {
            "A": "Διαβάζει το κείμενο μόνο από αριστερά προς τα δεξιά",
            "B": "Διαβάζει το κείμενο μόνο από δεξιά προς τα αριστερά",
            "C": "Διαβάζει ταυτόχρονα το κείμενο προς τα εμπρός και προς τα πίσω",
            "D": "Αγνοεί τη σειρά των λέξεων και κοιτάζει μόνο συχνότητες"
        },
        "explanation": "Το BERT διαβάζει ταυτόχρονα το κείμενο προς τα εμπρός και προς τα πίσω, κατανοώντας το νόημα με βάση τα συμφραζόμενα."
    },
    {
        "question": "Σε τι προσανατολίζεται κυρίως το μοντέλο GPT;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "Λίστα (7.5.4)"
        },
        "choices": {
            "A": "Στην αναγνώριση εικόνων και βίντεο",
            "B": "Στην ταξινόμηση ανεπιθύμητης αλληλογραφίας",
            "C": "Στην αποκλειστική μετάφραση κειμένων",
            "D": "Στη δημιουργία κειμένου (language generation)"
        },
        "explanation": "Το GPT (Generative Pre-trained Transformer) προσανατολίζεται στη δημιουργία κειμένου και χρησιμοποιείται για διαλογικά μοντέλα και συγγραφή."
    },
    {
        "question": "Ποιο μοντέλο embedding χρησιμοποιεί παγκόσμιες συσχετίσεις λέξεων σε μεγάλα σύνολα κειμένων;",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (GloVe)"
        },
        "choices": {
            "A": "GloVe",
            "B": "Bag-of-Words",
            "C": "RNN",
            "D": "TF-IDF"
        },
        "explanation": "Το GloVe (Global Vectors for Word Representation) χρησιμοποιεί παγκόσμιες συσχετίσεις των λέξεων σε ένα μεγάλο σύνολο κειμένων."
    },
    {
        "question": "Ποια τεχνική προεπεξεργασίας μετατρέπει το «kalispera :)» σε «καλησπέρα [χαμόγελο]»;",
        "answer": "B",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 219",
            "paragraph": "1η παράγραφος (Λίστα)"
        },
        "choices": {
            "A": "Stopword Removal",
            "B": "Διαχείριση Ειδικών Συμβόλων / Emoticons",
            "C": "Stemming",
            "D": "Tokenization"
        },
        "explanation": "Η διαχείριση ειδικών συμβόλων και emoticons περιλαμβάνει την επέκταση ή μετατροπή εναλλακτικών μορφών έκφρασης σε κανονικό κείμενο."
    },
    {
        "question": "Πώς αντιμετωπίζει το FastText τις λέξεις που δεν έχει ξαναδεί (out-of-vocabulary);",
        "answer": "C",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (FastText)"
        },
        "choices": {
            "A": "Τις αγνοεί πλήρως και τις διαγράφει",
            "B": "Τις αντικαθιστά με τυχαία διανύσματα",
            "C": "Χρησιμοποιεί υποσυστήματα λέξεων (π.χ. προθέματα) για να τις κατανοήσει",
            "D": "Ζητάει από τον χρήστη να τις ορίσει χειροκίνητα"
        },
        "explanation": "Το FastText λαμβάνει υπόψη τα υποσυστήματα των λέξεων, κάτι που βοηθά στην κατανόηση λέξεων βάσει της μορφολογίας τους ακόμα κι αν είναι νέες."
    },
    {
        "question": "Τι τύπου μάθηση χρησιμοποιείται συνήθως στην Ταξινόμηση Κειμένου;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "1η παράγραφος (Ταξινόμηση Κειμένου)"
        },
        "choices": {
            "A": "Μη επιβλεπόμενη μάθηση (Unsupervised learning)",
            "B": "Ενισχυτική μάθηση (Reinforcement learning)",
            "C": "Αυτοματοποιημένη μάθηση κανόνων",
            "D": "Εποπτευόμενη μάθηση (Supervised learning)"
        },
        "explanation": "Η ταξινόμηση γίνεται συνήθως με χρήση εποπτευόμενης μάθησης, αξιοποιώντας προηγούμενα παραδείγματα κειμένων με ετικέτες."
    },
    {
        "question": "Ποιο από τα παρακάτω ΔΕΝ αποτελεί στάδιο της προεπεξεργασίας κειμένου;",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 218-219",
            "paragraph": "Ενότητα 7.2"
        },
        "choices": {
            "A": "Εκπαίδευση Νευρωνικού Δικτύου",
            "B": "Κανονικοποίηση Κειμένου",
            "C": "Διαχωρισμός Λέξεων (Tokenization)",
            "D": "Αφαίρεση Λέξεων Κοινής Χρήσης"
        },
        "explanation": "Η εκπαίδευση νευρωνικού δικτύου είναι στάδιο μοντελοποίησης, όχι προεπεξεργασίας. Τα υπόλοιπα (Κανονικοποίηση, Tokenization, Stopword Removal) είναι στάδια προεπεξεργασίας."
    },
    {
        "question": "Ποια είναι η σημασία της «Αυτοπροσοχής» (Self-Attention) στους Transformers;",
        "answer": "B",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.3)"
        },
        "choices": {
            "A": "Επιτρέπει στο μοντέλο να διορθώνει αυτόματα τα ορθογραφικά λάθη",
            "B": "Επιτρέπει τον εντοπισμό σημαντικών λέξεων ανεξαρτήτως της θέσης τους",
            "C": "Βοηθά το μοντέλο να ξεχνάει άχρηστες πληροφορίες αμέσως",
            "D": "Αυξάνει τον αριθμό των δεδομένων εισόδου αυτόματα"
        },
        "explanation": "Η αυτοπροσοχή επιτρέπει στο μοντέλο να εστιάζει και να εντοπίζει σημαντικές λέξεις μέσα σε μία πρόταση ανεξαρτήτως της σειράς ή της θέσης τους."
    },
    {
        "question": "Ποια χρονολογία εισήχθησαν οι Μετασχηματιστές (Transformers) με το άρθρο “Attention is All You Need”;",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.3)"
        },
        "choices": {
            "A": "2010",
            "B": "2015",
            "C": "2017",
            "D": "2020"
        },
        "explanation": "Οι μετασχηματιστές εισήχθησαν το 2017 με το εμβληματικό άρθρο “Attention is All You Need”."
    },
    {
        "question": "Ποια λέξη στο παράδειγμα «15 Μαρτίου» αναγνωρίζεται ως οντότητα από το NER;",
        "answer": "D",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "Λίστα (NER)"
        },
        "choices": {
            "A": "Οργανισμός",
            "B": "Τοποθεσία",
            "C": "Πρόσωπο",
            "D": "Ημερομηνία"
        },
        "explanation": "Στο παράδειγμα του κειμένου, το «15 Μαρτίου» κατατάσσεται στην κατηγορία «Ημερομηνίες και ποσά»."
    },
    {
        "question": "Ποια μέθοδος embedding δίνει διαφορετικό διάνυσμα στην ίδια λέξη ανάλογα με το context;",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (Contextualized Embeddings)"
        },
        "choices": {
            "A": "ELMo",
            "B": "Word2Vec",
            "C": "GloVe",
            "D": "TF-IDF"
        },
        "explanation": "Τα μοντέλα όπως το ELMo (και BERT, GPT) ανήκουν στα Contextualized Embeddings, όπου η αναπαράσταση της λέξης αλλάζει ανάλογα με τα συμφραζόμενα."
    },
    {
        "question": "Τι είδους δεδομένα επεξεργάζονται κυρίως τα RNN;",
        "answer": "B",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.1)"
        },
        "choices": {
            "A": "Στατικές εικόνες υψηλής ανάλυσης",
            "B": "Δεδομένα ακολουθίας (sequential data)",
            "C": "Πίνακες δεδομένων χωρίς χρονική σειρά",
            "D": "Τρισδιάστατα γραφικά μοντέλα"
        },
        "explanation": "Τα RNN σχεδιάστηκαν ειδικά για να επεξεργάζονται δεδομένα ακολουθίας, όπως κείμενα, όπου η σειρά των στοιχείων έχει σημασία."
    },
    {
        "question": "Ποιο από τα παρακάτω είναι παράδειγμα οντότητας «Τοποθεσία» στο NER;",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "Λίστα (NER)"
        },
        "choices": {
            "A": "Google",
            "B": "15 Μαρτίου",
            "C": "Αθήνα",
            "D": "200 ευρώ"
        },
        "explanation": "Σύμφωνα με το κείμενο, η «Αθήνα» και η «Ελλάδα» δίνονται ως παραδείγματα για την κατηγορία «Ονόματα τοποθεσιών»."
    },
    {
        "question": "Ποιο μοντέλο θεωρείται βελτίωση του Word2Vec για μορφολογικά πλούσιες γλώσσες;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (FastText)"
        },
        "choices": {
            "A": "BERT",
            "B": "RNN",
            "C": "LSTM",
            "D": "FastText"
        },
        "explanation": "Το FastText αναφέρεται ως επέκταση του Word2Vec που είναι ιδιαίτερα χρήσιμη σε γλώσσες με πλούσια μορφολογία όπως τα ελληνικά."
    },
    {
        "question": "Ποια είναι η λειτουργία των «πυλών» (gates) στα LSTM;",
        "answer": "A",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.2)"
        },
        "choices": {
            "A": "Αποφασίζουν ποιες πληροφορίες θα διατηρηθούν και ποιες θα ξεχαστούν",
            "B": "Μετατρέπουν το κείμενο σε εικόνα",
            "C": "Αυξάνουν την ταχύτητα εκπαίδευσης κατά 100%",
            "D": "Συνδέουν το δίκτυο απευθείας με το διαδίκτυο"
        },
        "explanation": "Τα LSTM χρησιμοποιούν πύλες (gates) για να ελέγχουν τη ροή της πληροφορίας, αποφασίζοντας τι να κρατήσουν στη μνήμη και τι να απορρίψουν."
    },
    {
        "question": "Ποιο σύγχρονο μοντέλο NLP είναι παραλλαγή του BERT;",
        "answer": "B",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "Τελευταία λίστα"
        },
        "choices": {
            "A": "Word2Vec",
            "B": "RoBERTa",
            "C": "TF-IDF",
            "D": "GloVe"
        },
        "explanation": "Το RoBERTa αναφέρεται ως μία από τις παραλλαγές των γλωσσικών μοντέλων που βασίζονται στην αρχιτεκτονική του BERT/Transformers."
    },
    {
        "question": "Τι είδους εφαρμογή είναι η Siri και η Alexa;",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 216-217",
            "paragraph": "1.1.2 (από context 7.1)"
        },
        "choices": {
            "A": "Συστήματα βιομηχανικής παραγωγής",
            "B": "Εργαλεία αποκλειστικά για γραπτή μετάφραση",
            "C": "Προσωπικοί βοηθοί φωνής",
            "D": "Συστήματα καθαρισμού δεδομένων"
        },
        "explanation": "Αν και η αναφορά είναι γενική στο βιβλίο, στο κεφάλαιο 7.1 (σελ. 216) γίνεται αναφορά στην καθημερινή χρήση NLP, όπου εντάσσονται οι φωνητικοί βοηθοί."
    },
    {
        "question": "Ποιο βήμα προεπεξεργασίας μετατρέπει το «έτρεξε» σε «τρέχω»;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (7.2)"
        },
        "choices": {
            "A": "Tokenization",
            "B": "Stopword Removal",
            "C": "Text Normalization",
            "D": "Lemmatization"
        },
        "explanation": "Η Λημματοποίηση (Lemmatization) είναι η διαδικασία που επιστρέφει τη γραμματική βασική μορφή της λέξης, π.χ. από «έτρεξε» σε «τρέχω»."
    },
    {
        "question": "Ποιο μοντέλο χρησιμοποιείται για τη δημιουργία κειμένου και αυτόματες περιλήψεις;",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "Λίστα (7.5.4)"
        },
        "choices": {
            "A": "GPT",
            "B": "BERT",
            "C": "Word2Vec",
            "D": "RNN"
        },
        "explanation": "Το GPT (Generative Pre-trained Transformer) εξειδικεύεται στη δημιουργία κειμένου (language generation), όπως αυτόματες περιλήψεις και συγγραφή."
    },
    {
        "question": "Ποια είναι η κύρια διαφορά μεταξύ Bag-of-Words και Word Embeddings;",
        "answer": "B",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "1η & 2η παράγραφος"
        },
        "choices": {
            "A": "Το Bag-of-Words είναι πιο σύγχρονο από τα Embeddings",
            "B": "Τα Embeddings κατανοούν σημασιολογικές σχέσεις, το Bag-of-Words όχι",
            "C": "Το Bag-of-Words χρησιμοποιεί νευρωνικά δίκτυα, τα Embeddings όχι",
            "D": "Τα Embeddings απαιτούν λιγότερη μνήμη από το Bag-of-Words"
        },
        "explanation": "Η θεμελιώδης διαφορά είναι ότι το Bag-of-Words αγνοεί τη σημασία, ενώ τα Embeddings τοποθετούν λέξεις με παρόμοιο νόημα κοντά στον διανυσματικό χώρο."
    },
    {
        "question": "Τι κάνει το Text Normalization με τους αριθμούς και τα σύμβολα;",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (7.2)"
        },
        "choices": {
            "A": "Τα μετατρέπει σε λέξεις ολογράφως",
            "B": "Τα πολλαπλασιάζει για να βρει μέσο όρο",
            "C": "Τα αφαιρεί για να μειώσει την πολυπλοκότητα",
            "D": "Τα αντικαθιστά με τυχαίους χαρακτήρες"
        },
        "explanation": "Η Κανονικοποίηση Κειμένου περιλαμβάνει την αφαίρεση σημείων στίξης, αριθμών και ειδικών συμβόλων για απλοποίηση του κειμένου."
    },
    {
        "question": "Ποιο εργαλείο NLP θα χρησιμοποιούσατε για να εντοπίσετε αν ένα σχόλιο είναι αρνητικό;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 221",
            "paragraph": "1η παράγραφος (7.4)"
        },
        "choices": {
            "A": "Named Entity Recognition",
            "B": "Lemmatization",
            "C": "Tokenization",
            "D": "Sentiment Analysis"
        },
        "explanation": "Η Ανάλυση Συναισθήματος (Sentiment Analysis) είναι η κατάλληλη τεχνική για τον εντοπισμό και την κατηγοριοποίηση του συναισθήματος ενός κειμένου."
    },
    {
        "question": "Τι αντιπροσωπεύουν τα tokens στη διαδικασία Tokenization;",
        "answer": "A",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (7.2)"
        },
        "choices": {
            "A": "Επιμέρους λέξεις ή φράσεις μιας πρότασης",
            "B": "Τους χαρακτήρες ASCII του κειμένου",
            "C": "Τα σημεία στίξης που αφαιρούνται",
            "D": "Τις ρίζες των λέξεων μόνο"
        },
        "explanation": "Τα tokens είναι τα κομμάτια στα οποία διαχωρίζεται η πρόταση, συνήθως λέξεις ή φράσεις."
    },
    {
        "question": "Ποια τεχνική είναι απαραίτητη πριν την εφαρμογή αλγορίθμων σε κείμενο;",
        "answer": "B",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 219",
            "paragraph": "1η παράγραφος (7.3)"
        },
        "choices": {
            "A": "Η μετάφραση του κειμένου στα Αγγλικά",
            "B": "Η μετατροπή του κειμένου σε αριθμούς (Vectorization)",
            "C": "Η εκτύπωση του κειμένου σε χαρτί",
            "D": "Η αλφαβητική ταξινόμηση των προτάσεων"
        },
        "explanation": "Για να επεξεργαστεί ένα σύστημα φυσική γλώσσα, είναι απαραίτητη η διανυσματοποίηση, δηλαδή η μετατροπή των λέξεων σε αριθμούς."
    },
    {
        "question": "Ποιο πρόβλημα λύνουν τα Contextualized Embeddings που δεν λύνει το Word2Vec;",
        "answer": "C",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (Contextualized Embeddings)"
        },
        "choices": {
            "A": "Το πρόβλημα της αργής εκπαίδευσης",
            "B": "Το πρόβλημα των ορθογραφικών λαθών",
            "C": "Το πρόβλημα της πολυσημίας (διαφορετική σημασία ανάλογα με το context)",
            "D": "Το πρόβλημα της έλλειψης δεδομένων"
        },
        "explanation": "Τα Contextualized Embeddings αποδίδουν διαφορετικά διανύσματα στην ίδια λέξη ανάλογα με το context, λύνοντας το πρόβλημα της πολυσημίας που έχουν τα στατικά μοντέλα."
    },
    {
        "question": "Σε ποια κατηγορία εφαρμογών ανήκει η αυτόματη κατάταξη ειδήσεων σε 'πολιτικά' ή 'αθλητικά';",
        "answer": "D",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "1η παράγραφος (Ταξινόμηση Κειμένου)"
        },
        "choices": {
            "A": "Sentiment Analysis",
            "B": "Machine Translation",
            "C": "Named Entity Recognition",
            "D": "Text Classification"
        },
        "explanation": "Το παράδειγμα κατάταξης άρθρων σε κατηγορίες όπως 'αθλητικό' ή 'πολιτικό' ανήκει στην Ταξινόμηση Κειμένου (Text Classification)."
    },
    {
        "question": "Ποια τεχνολογία χρησιμοποιούν τα σύγχρονα μοντέλα NER για καλύτερα αποτελέσματα;",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "Τελευταία παράγραφος (NER)"
        },
        "choices": {
            "A": "Βαθιά μάθηση και μετασχηματιστές",
            "B": "Αποκλειστικά λεξικά κανόνων",
            "C": "Χειροκίνητη επιλογή από ανθρώπους",
            "D": "Απλούς αλγορίθμους ταξινόμησης"
        },
        "explanation": "Οι πιο εξελιγμένες εφαρμογές NER χρησιμοποιούν βαθιά μάθηση και μετασχηματιστές για να αναγνωρίζουν οντότητες σε περίπλοκα συμφραζόμενα."
    },
    {
        "question": "Τι είναι το 'vanishing gradient problem' στα RNN;",
        "answer": "B",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "2η παράγραφος (7.5.1)"
        },
        "choices": {
            "A": "Η αδυναμία του δικτύου να επεξεργαστεί εικόνες",
            "B": "Η δυσκολία διατήρησης πληροφορίας από μακρινά σημεία της ακολουθίας",
            "C": "Η υπερβολική αύξηση των παραμέτρων του δικτύου",
            "D": "Η απώλεια των δεδομένων εξόδου"
        },
        "explanation": "Το vanishing gradient problem αναφέρεται στη δυσκολία των RNN να διατηρήσουν και να μεταφέρουν σημαντικές πληροφορίες από την αρχή μακροσκελών ακολουθιών."
    },
    {
        "question": "Ποιο μοντέλο εισήγαγε την έννοια της αυτοπροσοχής (self-attention);",
        "answer": "C",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.3)"
        },
        "choices": {
            "A": "LSTM",
            "B": "RNN",
            "C": "Transformers",
            "D": "Word2Vec"
        },
        "explanation": "Οι Transformers, που παρουσιάστηκαν το 2017, βασίζονται στον μηχανισμό της αυτοπροσοχής (self-attention)."
    },
    {
        "question": "Ποιο από τα παρακάτω είναι χαρακτηριστικό του mBERT;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "Λίστα (7.5.4)"
        },
        "choices": {
            "A": "Είναι ένα μοντέλο αποκλειστικά για εικόνες",
            "B": "Λειτουργεί μόνο στα Αγγλικά",
            "C": "Χρησιμοποιεί μόνο RNN αρχιτεκτονική",
            "D": "Βελτιώνει την απόδοση σε πολυγλωσσικά περιβάλλοντα"
        },
        "explanation": "Το mBERT (multilingual BERT) είναι μια παραλλαγή που βελτιώνει την απόδοση σε πολυγλωσσικά περιβάλλοντα."
    },
    {
        "question": "Τι κάνει η Λημματοποίηση (Lemmatization) στη λέξη 'τρέχει';",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (7.2)"
        },
        "choices": {
            "A": "Την μετατρέπει στο 'τρέχω'",
            "B": "Την μετατρέπει στο 'τρεχ'",
            "C": "Την αφαιρεί ως stopword",
            "D": "Την μετατρέπει σε αριθμό"
        },
        "explanation": "Η λημματοποίηση επιστρέφει τη γραμματική βασική μορφή, δηλαδή το ρήμα στον ενεστώτα πρώτου προσώπου (τρέχω), σε αντίθεση με το stemming που θα έδινε τη ρίζα."
    },
    {
        "question": "Ποιο από τα παρακάτω ΔΕΝ είναι μέθοδος διανυσματοποίησης;",
        "answer": "B",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 219-220",
            "paragraph": "Ενότητα 7.3"
        },
        "choices": {
            "A": "Bag-of-Words",
            "B": "Spelling Correction",
            "C": "TF-IDF",
            "D": "Word2Vec"
        },
        "explanation": "Το Spelling Correction είναι μέθοδος προεπεξεργασίας (διόρθωση ορθογραφίας), όχι μέθοδος διανυσματοποίησης (μετατροπής σε αριθμούς)."
    },
    {
        "question": "Ποιο είναι το αποτέλεσμα της εντολής «Text Normalization» στην πρόταση «Καλημέρα! Τι κάνεις;»;",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (7.2)"
        },
        "choices": {
            "A": "«Καλημέρα Τι κάνεις»",
            "B": "«καλημερα»",
            "C": "«καλημερα τι κανεις»",
            "D": "«ΚΑΛΗΜΕΡΑ ΤΙ ΚΑΝΕΙΣ»"
        },
        "explanation": "Σύμφωνα με το παράδειγμα, η κανονικοποίηση μετατρέπει σε πεζά και αφαιρεί σημεία στίξης: «καλημερα τι κανεις»."
    },
    {
        "question": "Ποια λέξη είναι πιθανό να αφαιρεθεί κατά το «Stopword Removal»;",
        "answer": "D",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (7.2)"
        },
        "choices": {
            "A": "Τεχνητή",
            "B": "Νοημοσύνη",
            "C": "Υπολογιστής",
            "D": "Και"
        },
        "explanation": "Λέξεις όπως «και», «ο», «η», «σε» αναφέρονται ως stopwords που αφαιρούνται επειδή δεν προσθέτουν ιδιαίτερη σημασία."
    },
    {
        "question": "Πώς ονομάζεται η διαδικασία όπου το κείμενο «Η τεχνητή νοημοσύνη» γίνεται [‘Η’, ‘τεχνητή’, ‘νοημοσύνη’];",
        "answer": "A",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (7.2)"
        },
        "choices": {
            "A": "Tokenization",
            "B": "Vectorization",
            "C": "Normalization",
            "D": "Summarization"
        },
        "explanation": "Αυτό είναι το κλασικό παράδειγμα Tokenization, όπου η πρόταση σπάει σε λίστα λέξεων (tokens)."
    },
    {
        "question": "Τι σημαίνει το TF στο ακρωνύμιο TF-IDF;",
        "answer": "B",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 219",
            "paragraph": "Λίστα (7.3)"
        },
        "choices": {
            "A": "Total Frequency",
            "B": "Term Frequency",
            "C": "Text Format",
            "D": "Token Finding"
        },
        "explanation": "Το TF σημαίνει Term Frequency (Συχνότητα Όρου) και μετρά πόσο συχνά εμφανίζεται μια λέξη σε ένα έγγραφο."
    },
    {
        "question": "Ποιο μοντέλο NLP είναι κατάλληλο για ερωταποκρίσεις (Q&A);",
        "answer": "C",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "Λίστα (BERT)"
        },
        "choices": {
            "A": "BoW",
            "B": "Word2Vec",
            "C": "BERT",
            "D": "K-Means"
        },
        "explanation": "Το BERT αναφέρεται ως ιδανικό για εργασίες όπως κατηγοριοποίηση, NER και ερωταποκρίσεις."
    },
    {
        "question": "Ποιο χαρακτηριστικό των Transformers τους καθιστά ταχύτερους από τα RNN;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "1η παράγραφος"
        },
        "choices": {
            "A": "Η μικρότερη ακρίβεια",
            "B": "Η χρήση λιγότερων δεδομένων",
            "C": "Η απλότητα του κώδικα",
            "D": "Η δυνατότητα παράλληλης επεξεργασίας"
        },
        "explanation": "Οι μετασχηματιστές υποστηρίζουν παράλληλη επεξεργασία, κάτι που τους δίνει πλεονέκτημα ταχύτητας έναντι των σειριακών RNN."
    },
    {
        "question": "Ποιο είδος οντότητας είναι το «200 ευρώ» στην ανάλυση NER;",
        "answer": "A",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "Λίστα (NER)"
        },
        "choices": {
            "A": "Ποσό",
            "B": "Τοποθεσία",
            "C": "Οργανισμός",
            "D": "Γεγονός"
        },
        "explanation": "Το «200 ευρώ» δίνεται ως παράδειγμα στην κατηγορία «Ημερομηνίες και ποσά»."
    },
    {
        "question": "Τι προσφέρει η τεχνική «Spelling Correction»;",
        "answer": "B",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 218",
            "paragraph": "Λίστα (7.2)"
        },
        "choices": {
            "A": "Αφαιρεί τις λέξεις με λίγα γράμματα",
            "B": "Διορθώνει ορθογραφικά λάθη σε πρόχειρα κείμενα",
            "C": "Μετατρέπει το κείμενο σε κεφαλαία",
            "D": "Αλλάζει τη γραμματοσειρά του κειμένου"
        },
        "explanation": "Ο Ορθογραφικός Έλεγχος (Spelling Correction) διορθώνει ορθογραφικά λάθη, ειδικά σε ανεπίσημα κείμενα."
    },
    {
        "question": "Ποιο από τα παρακάτω είναι παράδειγμα «Οργανισμού» στο NER;",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "Λίστα (NER)"
        },
        "choices": {
            "A": "Γερμανία",
            "B": "Γιάννης",
            "C": "Google",
            "D": "Δευτέρα"
        },
        "explanation": "Η «Google» και η «Ευρωπαϊκή Ένωση» αναφέρονται ως παραδείγματα Οργανισμών."
    },
    {
        "question": "Ποια είναι η βασική μονάδα εισόδου σε ένα μοντέλο Bag-of-Words;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 219",
            "paragraph": "2η παράγραφος (7.3)"
        },
        "choices": {
            "A": "Η σειρά των λέξεων",
            "B": "Το συντακτικό της πρότασης",
            "C": "Το συναίσθημα της λέξης",
            "D": "Η συχνότητα εμφάνισης των λέξεων"
        },
        "explanation": "Το Bag-of-Words βασίζεται αποκλειστικά στη συχνότητα εμφάνισης των λέξεων, αγνοώντας τη σειρά ή τη γραμματική."
    },
    {
        "question": "Γιατί τα LSTM είναι καλύτερα από τα απλά RNN στην αναγνώριση ομιλίας;",
        "answer": "A",
        "difficulty": "hard",
        "reference": {
            "page": "σελ. 223",
            "paragraph": "1η παράγραφος (7.5.2)"
        },
        "choices": {
            "A": "Διαχειρίζονται καλύτερα τις μακροχρόνιες εξαρτήσεις στην ακολουθία",
            "B": "Δεν χρειάζονται δεδομένα εκπαίδευσης",
            "C": "Είναι πιο απλά στην κατασκευή τους",
            "D": "Λειτουργούν χωρίς καθόλου μνήμη"
        },
        "explanation": "Τα LSTM σχεδιάστηκαν για να κατανοούν πολύπλοκες συσχετίσεις σε μακροχρόνιες ακολουθίες, κάτι κρίσιμο για την ομιλία."
    },
    {
        "question": "Ποιο μοντέλο θα επιλέγατε για να δημιουργήσετε ένα chatbot που απαντάει φυσικά;",
        "answer": "B",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "Λίστα (GPT)"
        },
        "choices": {
            "A": "BoW",
            "B": "GPT",
            "C": "CNN",
            "D": "K-Means"
        },
        "explanation": "Το GPT χρησιμοποιείται για διαλογικά μοντέλα και δημιουργία κειμένου, άρα είναι ιδανικό για chatbots."
    },
    {
        "question": "Ποια είναι η σχέση μεταξύ NLP και AI;",
        "answer": "C",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 216",
            "paragraph": "Εισαγωγή 7.1 (γενικό πλαίσιο)"
        },
        "choices": {
            "A": "Το NLP είναι εντελώς ανεξάρτητο από το AI",
            "B": "Το AI είναι υποκατηγορία του NLP",
            "C": "Το NLP είναι κλάδος της Τεχνητής Νοημοσύνης",
            "D": "Το NLP αντικατέστησε το AI"
        },
        "explanation": "Το NLP ορίζεται ως κλάδος της επιστήμης υπολογιστών και της Τεχνητής Νοημοσύνης."
    },
    {
        "question": "Τι είδους μάθηση απαιτεί συνήθως η εκπαίδευση ενός μοντέλου NER;",
        "answer": "D",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 222",
            "paragraph": "Συνάγεται από την ενότητα Ταξινόμηση/NER"
        },
        "choices": {
            "A": "Μη επιβλεπόμενη (Unsupervised)",
            "B": "Ενισχυτική (Reinforcement)",
            "C": "Τυχαία (Random)",
            "D": "Εποπτευόμενη (Supervised) με ετικέτες"
        },
        "explanation": "Όπως και η ταξινόμηση, το NER βασίζεται σε δεδομένα όπου οι οντότητες είναι ήδη επισημασμένες (ετικέτες), άρα Supervised Learning."
    },
    {
        "question": "Ποιο είναι το κύριο χαρακτηριστικό της «Γλωσσικής Μοντελοποίησης» (Language Modeling);",
        "answer": "A",
        "difficulty": "medium",
        "reference": {
            "page": "σελ. 224",
            "paragraph": "7.5.4"
        },
        "choices": {
            "A": "Η εκμάθηση της δομής της γλώσσας από μεγάλα σύνολα κειμένου",
            "B": "Η απλή καταμέτρηση λέξεων σε ένα βιβλίο",
            "C": "Η μετάφραση λέξη προς λέξη",
            "D": "Η μετατροπή κειμένου σε ήχο"
        },
        "explanation": "Τα γλωσσικά μοντέλα μαθαίνουν τη δομή και τους κανόνες της γλώσσας επεξεργαζόμενα τεράστια σύνολα κειμένου."
    },
    {
        "question": "Ποιο μοντέλο χρησιμοποιεί «Global Vectors»;",
        "answer": "B",
        "difficulty": "easy",
        "reference": {
            "page": "σελ. 220",
            "paragraph": "Λίστα (GloVe)"
        },
        "choices": {
            "A": "Word2Vec",
            "B": "GloVe",
            "C": "BERT",
            "D": "FastText"
        },
        "explanation": "Το όνομα GloVe προέρχεται από το Global Vectors for Word Representation."
    }
]
