[
  {
    "question": "Ποιο είναι το θεμελιώδες χαρακτηριστικό της Ενισχυτικής Μάθησης (Reinforcement Learning);",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 234",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Η εκπαίδευση με χρήση αποκλειστικά επισημειωμένων δεδομένων από ανθρώπους.",
      "B": "Η μάθηση μέσω της αλληλεπίδρασης με το περιβάλλον με τη μέθοδο δοκιμής και σφάλματος.",
      "C": "Η ταξινόμηση δεδομένων σε κατηγορίες χωρίς καμία ανατροφοδότηση.",
      "D": "Η δημιουργία στατικών κανόνων προγραμματισμού που δεν αλλάζουν ποτέ."
    },
    "explanation": "Η ενισχυτική μάθηση βασίζεται στην αλληλεπίδραση του πράκτορα με το περιβάλλον και τη μάθηση μέσω της διαδικασίας δοκιμής και σφάλματος, όπως αναφέρεται στην εισαγωγή."
  },
  {
    "question": "Ποια είναι τα δύο βασικά συστατικά μέρη ενός συστήματος ενισχυτικής μάθησης;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Ο διακομιστής και ο πελάτης.",
      "B": "Τα δεδομένα εισόδου και η βάση δεδομένων.",
      "C": "Ο πράκτορας (agent) και το περιβάλλον (environment).",
      "D": "Το νευρωνικό δίκτυο και ο σκληρός δίσκος."
    },
    "explanation": "Όπως περιγράφεται στα στοιχεία σχεδίασης, τα δύο θεμελιώδη μέρη είναι ο πράκτορας που δρα και το περιβάλλον που αντιδρά."
  },
  {
    "question": "Τι λαμβάνει ο πράκτορας από το περιβάλλον ως απάντηση σε κάθε ενέργειά του;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Μια ανταμοιβή (reward) ή ποινή και τη νέα κατάσταση.",
      "B": "Έναν πλήρη χάρτη όλων των πιθανών μελλοντικών καταστάσεων.",
      "C": "Μια λίστα με όλες τις λανθασμένες κινήσεις που έκανε.",
      "D": "Έναν αλγόριθμο για την επίλυση του προβλήματος."
    },
    "explanation": "Η ανατροφοδότηση που λαμβάνει ο πράκτορας από το περιβάλλον είναι η ανταμοιβή (θετική ή αρνητική) και η παρατήρηση της νέας κατάστασης."
  },
  {
    "question": "Τι ορίζεται ως «Πολιτική» (Policy) στην ενισχυτική μάθηση;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 236",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Ο συνολικός χρόνος που απαιτείται για την εκπαίδευση.",
      "B": "Το σύνολο των δεδομένων που αποθηκεύονται στη μνήμη.",
      "C": "Η φυσική τοποθεσία του πράκτορα στο χώρο.",
      "D": "Η στρατηγική που καθορίζει την ενέργεια του πράκτορα σε κάθε κατάσταση."
    },
    "explanation": "Η πολιτική είναι ο κανόνας ή η στρατηγική που υπαγορεύει ποια ενέργεια πρέπει να επιλέξει ο πράκτορας δεδομένης μιας συγκεκριμένης κατάστασης."
  },
  {
    "question": "Ποιος είναι ο στόχος της «Συνάρτησης Αξίας» (Value Function);",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 236",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Να εκτιμήσει τη μακροπρόθεσμη αναμενόμενη ανταμοιβή από μια κατάσταση.",
      "B": "Να μετρήσει την ταχύτητα του επεξεργαστή.",
      "C": "Να καθορίσει το χρώμα του περιβάλλοντος.",
      "D": "Να διαγράψει τις λανθασμένες ενέργειες."
    },
    "explanation": "Η συνάρτηση αξίας προβλέπει το συνολικό ποσό ανταμοιβής που αναμένεται να συγκεντρώσει ο πράκτορας στο μέλλον ξεκινώντας από μια κατάσταση."
  },
  {
    "question": "Τι συνδυάζει η Βαθιά Ενισχυτική Μάθηση (Deep Reinforcement Learning - DRL);",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Τη στατιστική ανάλυση με τη γραμμική άλγεβρα.",
      "B": "Τα βαθιά νευρωνικά δίκτυα με την ενισχυτική μάθηση.",
      "C": "Τον προγραμματισμό σε C++ με τη χρήση βάσεων δεδομένων SQL.",
      "D": "Τη ρομποτική με την τρισδιάστατη εκτύπωση."
    },
    "explanation": "Η DRL ενσωματώνει βαθιά νευρωνικά δίκτυα για να επιτρέψει στους πράκτορες να μαθαίνουν σε πολύπλοκα περιβάλλοντα με πολλές διαστάσεις."
  },
  {
    "question": "Ποια μέθοδος στοχεύει στην άμεση βελτιστοποίηση της πολιτικής αντί της συνάρτησης αξίας;",
    "answer": "C",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Q-Learning.",
      "B": "Value Iteration.",
      "C": "Policy Gradient.",
      "D": "Monte Carlo Tree Search."
    },
    "explanation": "Οι μέθοδοι Policy Gradient βελτιστοποιούν απευθείας την πολιτική του πράκτορα, προσαρμόζοντας τις παραμέτρους της για μεγιστοποίηση της ανταμοιβής."
  },
  {
    "question": "Ποια είναι τα δύο κύρια συστατικά των μοντέλων Actor-Critic;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Ο Server και ο Client.",
      "B": "Ο Encoder και ο Decoder.",
      "C": "Ο Generator και ο Discriminator.",
      "D": "Ο Actor (Δράστης) και ο Critic (Κριτής)."
    },
    "explanation": "Τα μοντέλα αυτά αποτελούνται από τον Actor, που επιλέγει ενέργειες, και τον Critic, που αξιολογεί τις ενέργειες αυτές."
  },
  {
    "question": "Τι προσφέρει η Ιεραρχική Ενισχυτική Μάθηση (HRL);",
    "answer": "A",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Τη διάσπαση ενός προβλήματος σε μικρότερα υπο-προβλήματα.",
      "B": "Την αύξηση του μεγέθους των νευρωνικών δικτύων χωρίς λόγο.",
      "C": "Την κατάργηση της ανάγκης για ανταμοιβές.",
      "D": "Την αποκλειστική χρήση ενός επιπέδου αποφάσεων."
    },
    "explanation": "Η HRL επιτρέπει την οργάνωση της συμπεριφοράς σε ιεραρχικά επίπεδα, διευκολύνοντας την επίλυση σύνθετων εργασιών μέσω υπο-στόχων."
  },
  {
    "question": "Τι χαρακτηρίζει τα Συστήματα Πολλαπλών Πρακτόρων (Multi-Agent Systems);",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 239",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Η ύπαρξη ενός μόνο παντοδύναμου πράκτορα.",
      "B": "Η αλληλεπίδραση πολλών πρακτόρων σε κοινό περιβάλλον.",
      "C": "Η έλλειψη οποιασδήποτε επικοινωνίας μεταξύ των μερών.",
      "D": "Η χρήση αποκλειστικά ανθρώπινων χειριστών."
    },
    "explanation": "Τα συστήματα αυτά περιλαμβάνουν πολλαπλούς νοήμονες πράκτορες που μοιράζονται το ίδιο περιβάλλον και αλληλεπιδρούν μεταξύ τους."
  },
  {
    "question": "Ποια είναι μια βασική πρόκληση στα Πολυπρακτορικά Συστήματα;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 239",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η χαμηλή ταχύτητα του διαδικτύου.",
      "B": "Η έλλειψη χρωμάτων στην οθόνη.",
      "C": "Η ισορροπία μεταξύ συνεργασίας και ανταγωνισμού.",
      "D": "Η αδυναμία χρήσης ηλεκτρικού ρεύματος."
    },
    "explanation": "Οι πράκτορες συχνά πρέπει να αποφασίσουν αν θα συνεργαστούν για κοινό όφελος ή θα ανταγωνιστούν για περιορισμένους πόρους."
  },
  {
    "question": "Τι περιγράφει το δίλημμα «Εξερεύνησης – Εκμετάλλευσης» (Exploration vs Exploitation);",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 241",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Την επιλογή μεταξύ δοκιμής νέων ενεργειών και χρήσης της ήδη γνωστής βέλτιστης.",
      "B": "Την απόφαση για το αν θα αγοραστεί νέος εξοπλισμός ή όχι.",
      "C": "Τη διαμάχη μεταξύ δύο διαφορετικών πρακτόρων.",
      "D": "Την επιλογή μεταξύ ενσύρματης και ασύρματης σύνδεσης."
    },
    "explanation": "Το δίλημμα αφορά το αν ο πράκτορας πρέπει να εξερευνήσει το περιβάλλον για πιθανές καλύτερες λύσεις ή να εκμεταλλευτεί την τρέχουσα γνώση του."
  },
  {
    "question": "Τι σημαίνει «Αραιή Ανταμοιβή» (Sparse Reward);",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Όταν ο πράκτορας λαμβάνει ανταμοιβή σε κάθε βήμα.",
      "B": "Όταν η ανταμοιβή είναι πάντα αρνητική.",
      "C": "Όταν ο πράκτορας δεν λαμβάνει ποτέ ανταμοιβή.",
      "D": "Όταν η ανταμοιβή δίνεται σπάνια και μόνο μετά από μακρά σειρά ενεργειών."
    },
    "explanation": "Σπανιότητα ανταμοιβών υπάρχει όταν το περιβάλλον δεν παρέχει συχνή ανατροφοδότηση, δυσκολεύοντας τον πράκτορα να καταλάβει ποια ενέργεια ήταν σωστή."
  },
  {
    "question": "Ποιο ηθικό ζήτημα προκύπτει από την ενισχυτική μάθηση;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Η κατανάλωση χαρτιού για εκτυπώσεις.",
      "B": "Η ευθυγράμμιση των στόχων του πράκτορα με τις ανθρώπινες αξίες.",
      "C": "Η υπερθέρμανση των κλιματιστικών.",
      "D": "Η δυσκολία στην εγκατάσταση λογισμικού."
    },
    "explanation": "Ένα βασικό ζήτημα είναι να διασφαλιστεί ότι οι στόχοι που βελτιστοποιεί ο πράκτορας δεν αντιβαίνουν στις ηθικές και κοινωνικές αξίες των ανθρώπων."
  },
  {
    "question": "Πώς εφαρμόζεται η ενισχυτική μάθηση στα ενεργειακά δίκτυα;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Για τη δυναμική διαχείριση της ζήτησης και προσφοράς ενέργειας.",
      "B": "Για την κατασκευή νέων καλωδίων.",
      "C": "Για την πρόσληψη προσωπικού στις εταιρείες ενέργειας.",
      "D": "Για τη χειροκίνητη καταγραφή των μετρητών."
    },
    "explanation": "Χρησιμοποιείται για την εξισορρόπηση του φορτίου και τη βελτιστοποίηση της διανομής ενέργειας σε πραγματικό χρόνο."
  },
  {
    "question": "Τι μαθαίνουν τα αυτόνομα οχήματα μέσω ενισχυτικής μάθησης;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Να αλλάζουν λάδια μόνα τους.",
      "B": "Να επιλέγουν τη μουσική για τον οδηγό.",
      "C": "Στρατηγικές πλοήγησης και αποφυγής εμποδίων.",
      "D": "Να πληρώνουν τέλη κυκλοφορίας."
    },
    "explanation": "Τα οχήματα μαθαίνουν να πλοηγούνται σε περίπλοκα περιβάλλοντα και να αντιδρούν σε δυναμικές συνθήκες κυκλοφορίας."
  },
  {
    "question": "Ποιος είναι ο ρόλος της ενισχυτικής μάθησης στη βιομηχανική αυτοματοποίηση;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η αύξηση της γραφειοκρατίας.",
      "B": "Η αντικατάσταση όλων των ανθρώπων από ρομπότ.",
      "C": "Η μείωση της ταχύτητας παραγωγής.",
      "D": "Η δημιουργία προσαρμοστικών συστημάτων παραγωγής."
    },
    "explanation": "Επιτρέπει στα συστήματα να προσαρμόζονται σε αλλαγές και να βελτιστοποιούν τις διαδικασίες συναρμολόγησης και παραγωγής."
  },
  {
    "question": "Στη μελέτη περίπτωσης του Κεφαλαίου 8, ποιο ήταν το κύριο πρόβλημα προς επίλυση;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 245",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η δυναμική διαχείριση μικροδικτύων με ανανεώσιμες πηγές.",
      "B": "Η κατασκευή ενός νέου εργοστασίου.",
      "C": "Η εκπαίδευση των υπαλλήλων σε σεμινάρια.",
      "D": "Η πώληση της εταιρείας σε επενδυτές."
    },
    "explanation": "Το πρόβλημα αφορούσε τη διαχείριση της αβεβαιότητας και της αστάθειας στην παραγωγή ενέργειας από ανανεώσιμες πηγές στα μικροδίκτυα."
  },
  {
    "question": "Ποια τεχνική χρησιμοποιήθηκε στη μελέτη περίπτωσης για την εκμάθηση πολιτικών;",
    "answer": "B",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 246",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Linear Regression.",
      "B": "Proximal Policy Optimization (PPO).",
      "C": "K-Means Clustering.",
      "D": "Genetic Algorithms."
    },
    "explanation": "Η μελέτη αναφέρει ρητά τη χρήση αλγορίθμων Deep Q-Learning και Proximal Policy Optimization (PPO)."
  },
  {
    "question": "Τι επέτρεψε η «Ανθεκτική Εξερεύνηση» (Robust Exploration) στη μελέτη περίπτωσης;",
    "answer": "C",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 246",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Την αύξηση του κόστους συντήρησης.",
      "B": "Την πλήρη διακοπή της παροχής ρεύματος.",
      "C": "Τη δοκιμή νέων ενεργειών χωρίς κίνδυνο για την ασφάλεια του δικτύου.",
      "D": "Την αγνόηση όλων των περιβαλλοντικών κανόνων."
    },
    "explanation": "Η στρατηγική αυτή επέτρεψε στους πράκτορες να εξερευνούν νέες λύσεις με ασφαλή τρόπο για τη λειτουργία του δικτύου."
  },
  {
    "question": "Τι είναι το MDP στην ενισχυτική μάθηση;",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Μια γλώσσα προγραμματισμού.",
      "B": "Markov Decision Process (Διαδικασία Απόφασης Markov).",
      "C": "Μια μονάδα μέτρησης απόστασης.",
      "D": "Ένας τύπος σκληρού δίσκου."
    },
    "explanation": "Το MDP είναι το μαθηματικό πλαίσιο που μοντελοποιεί το περιβάλλον στην ενισχυτική μάθηση."
  },
  {
    "question": "Ποια είναι η σχέση πράκτορα και περιβάλλοντος;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Κυκλική σχέση δράσης και αντίδρασης.",
      "B": "Γραμμική σχέση χωρίς επιστροφή.",
      "C": "Δεν υπάρχει καμία σχέση.",
      "D": "Είναι εντελώς ανεξάρτητοι."
    },
    "explanation": "Ο πράκτορας δρα στο περιβάλλον και το περιβάλλον αντιδρά δίνοντας νέα κατάσταση και ανταμοιβή, δημιουργώντας έναν κύκλο."
  },
  {
    "question": "Τι αντιπροσωπεύει η «Κατάσταση» (State) S;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 236",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Το όνομα του πράκτορα.",
      "B": "Τον αριθμό των βημάτων που απομένουν.",
      "C": "Την τελική βαθμολογία του παιχνιδιού.",
      "D": "Την τρέχουσα εικόνα ή περιγραφή του περιβάλλοντος."
    },
    "explanation": "Η κατάσταση περιγράφει την τρέχουσα θέση ή διαμόρφωση του περιβάλλοντος σε μια συγκεκριμένη χρονική στιγμή."
  },
  {
    "question": "Πώς ονομάζεται η διαδικασία όπου ο πράκτορας δοκιμάζει τυχαίες ενέργειες;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 241",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Εκμετάλλευση (Exploitation).",
      "B": "Βελτιστοποίηση (Optimization).",
      "C": "Εξερεύνηση (Exploration).",
      "D": "Στασιμότητα (Stagnation)."
    },
    "explanation": "Εξερεύνηση είναι η διαδικασία δοκιμής άγνωστων ενεργειών για την ανακάλυψη νέων, πιθανώς καλύτερων, στρατηγικών."
  },
  {
    "question": "Ποιο είναι το πλεονέκτημα των νευρωνικών δικτύων στην DRL;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Μπορούν να επεξεργαστούν πολύπλοκα δεδομένα όπως εικόνες.",
      "B": "Λειτουργούν χωρίς ρεύμα.",
      "C": "Είναι πάντα αλάνθαστα.",
      "D": "Δεν χρειάζονται καθόλου εκπαίδευση."
    },
    "explanation": "Τα νευρωνικά δίκτυα επιτρέπουν την επεξεργασία αισθητηριακών δεδομένων υψηλής διάστασης, όπως εικόνες βίντεο."
  },
  {
    "question": "Στα πολυπρακτορικά συστήματα, τι συμβαίνει στο «Συνεργατικό» σενάριο;",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 239",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Οι πράκτορες προσπαθούν να καταστρέψουν ο ένας τον άλλον.",
      "B": "Οι πράκτορες εργάζονται μαζί για έναν κοινό στόχο.",
      "C": "Οι πράκτορες αγνοούν ο ένας την ύπαρξη του άλλου.",
      "D": "Οι πράκτορες σταματούν να λειτουργούν."
    },
    "explanation": "Στη συνεργασία, όλοι οι πράκτορες συντονίζονται για να μεγιστοποιήσουν μια κοινή ανταμοιβή."
  },
  {
    "question": "Τι είναι η «Προσαρμοστική Ανατροφοδότηση» (Adaptive Reward Shaping) στη μελέτη περίπτωσης;",
    "answer": "C",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 246",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η αφαίρεση όλων των ανταμοιβών.",
      "B": "Η σταθερή ανταμοιβή ανεξαρτήτως αποτελέσματος.",
      "C": "Η διαμόρφωση των ανταμοιβών για εξισορρόπηση αποδοτικότητας και βιωσιμότητας.",
      "D": "Η τυχαία παροχή πόντων στους πράκτορες."
    },
    "explanation": "Πρόκειται για την προσαρμογή του μηχανισμού επιβράβευσης ώστε να καθοδηγεί τον πράκτορα προς τους επιθυμητούς στόχους."
  },
  {
    "question": "Ποια εφαρμογή αφορά τη ρύθμιση φαναριών σε πραγματικό χρόνο;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Βιομηχανική ρομποτική.",
      "B": "Αυτόνομα drones.",
      "C": "Ιατρική διάγνωση.",
      "D": "Ευφυή Συστήματα Κυκλοφορίας."
    },
    "explanation": "Τα ευφυή συστήματα κυκλοφορίας χρησιμοποιούν ΕΜ για τη δυναμική ρύθμιση της φωτεινής σηματοδότησης."
  },
  {
    "question": "Τι επιτρέπει η χρήση της Ενισχυτικής Μάθησης στα μικροδίκτυα;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 246",
      "paragraph": "5η παράγραφος"
    },
    "choices": {
      "A": "Την αυτοπροσαρμογή σε διαταραχές παραγωγής.",
      "B": "Την αύξηση της κατανάλωσης πετρελαίου.",
      "C": "Την κατάργηση των μπαταριών.",
      "D": "Την μείωση της ηλιοφάνειας."
    },
    "explanation": "Το σύστημα μπορεί να επαναπρογραμματίζει στρατηγικές αυτόματα όταν συμβαίνουν απρόβλεπτες αλλαγές."
  },
  {
    "question": "Ποιο είναι ένα παράδειγμα «μηδενικού αθροίσματος» (zero-sum) παιγνίου;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 240",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Η ομαδική εργασία σε ένα project.",
      "B": "Ο ανταγωνισμός όπου το κέρδος του ενός είναι ζημία του άλλου.",
      "C": "Η παράλληλη οδήγηση σε αυτοκινητόδρομο.",
      "D": "Η από κοινού συλλογή δεδομένων."
    },
    "explanation": "Σε ανταγωνιστικά περιβάλλοντα μηδενικού αθροίσματος, η επιτυχία του ενός πράκτορα σημαίνει αποτυχία του άλλου."
  },
  {
    "question": "Ποια είναι η δυσκολία της «μη-στασιμότητας» (non-stationarity) στα πολυπρακτορικά συστήματα;",
    "answer": "C",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 240",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Οι πράκτορες δεν κινούνται καθόλου.",
      "B": "Το περιβάλλον παραμένει πάντα ίδιο.",
      "C": "Το περιβάλλον αλλάζει συνεχώς λόγω των ενεργειών των άλλων πρακτόρων.",
      "D": "Τα δεδομένα είναι πολύ στατικά."
    },
    "explanation": "Επειδή όλοι οι πράκτορες μαθαίνουν και αλλάζουν ταυτόχρονα, το περιβάλλον δεν παραμένει σταθερό για κανέναν."
  },
  {
    "question": "Τι είναι τα Deep Q-Networks (DQN);",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Αλγόριθμοι που χρησιμοποιούν νευρωνικά δίκτυα για την προσέγγιση της συνάρτησης Q.",
      "B": "Δίκτυα υπολογιστών συνδεδεμένα με καλώδια Q.",
      "C": "Ερωτηματολόγια βαθιάς ανάλυσης.",
      "D": "Συστήματα αποθήκευσης κωδικών."
    },
    "explanation": "Τα DQN είναι μια μορφή DRL όπου ένα νευρωνικό δίκτυο μαθαίνει να προβλέπει την αξία Q των ενεργειών."
  },
  {
    "question": "Ποια είναι η έννοια της «Εκμετάλλευσης» (Exploitation);",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 241",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η καταστροφή του περιβάλλοντος.",
      "B": "Η επιλογή της ενέργειας που είναι γνωστό ότι δίνει τη μεγαλύτερη ανταμοιβή.",
      "C": "Η τυχαία επιλογή ενεργειών.",
      "D": "Η άρνηση λήψης οποιασδήποτε απόφασης."
    },
    "explanation": "Εκμετάλλευση είναι η χρήση της υφιστάμενης γνώσης για τη μεγιστοποίηση της άμεσης απόδοσης."
  },
  {
    "question": "Ποιο πρόβλημα αντιμετωπίζουν τα συστήματα ΕΜ σε περιβάλλοντα μεγάλης κλίμακας;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Έλλειψη χρωμάτων.",
      "B": "Υπερβολική απλότητα.",
      "C": "Υπολογιστική πολυπλοκότητα.",
      "D": "Χαμηλό κόστος."
    },
    "explanation": "Καθώς αυξάνεται ο αριθμός των καταστάσεων και ενεργειών, η υπολογιστική ισχύς που απαιτείται αυξάνεται εκθετικά."
  },
  {
    "question": "Τι συμβαίνει όταν οι στόχοι του πράκτορα δεν είναι σωστά ευθυγραμμισμένοι;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Ο πράκτορας σβήνει.",
      "B": "Ο πράκτορας γίνεται πιο γρήγορος.",
      "C": "Ο πράκτορας σταματά να μαθαίνει.",
      "D": "Μπορεί να προκύψουν απρόβλεπτες ή επιβλαβείς συμπεριφορές."
    },
    "explanation": "Η λανθασμένη ευθυγράμμιση στόχων (misalignment) μπορεί να οδηγήσει σε ενέργειες που είναι τεχνικά σωστές για το μοντέλο αλλά ανεπιθύμητες κοινωνικά."
  },
  {
    "question": "Ποιος αλγόριθμος αναφέρεται ως παράδειγμα μεθόδου Actor-Critic;",
    "answer": "A",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "A3C (Asynchronous Advantage Actor-Critic).",
      "B": "B2B (Business to Business).",
      "C": "C3PO (Protocol Droid).",
      "D": "D4RL (Datasets for RL)."
    },
    "explanation": "Ο A3C είναι ένας δημοφιλής αλγόριθμος που υλοποιεί την αρχιτεκτονική Actor-Critic."
  },
  {
    "question": "Σε ποιον τομέα η ΕΜ βοηθά στη «συνεργατική πλοήγηση σμήνους»;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 240",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Στη μαγειρική.",
      "B": "Στα drones και τη ρομποτική.",
      "C": "Στην αρχιτεκτονική κτιρίων.",
      "D": "Στην ιατρική χειρουργική."
    },
    "explanation": "Τα σμήνη drones χρησιμοποιούν πολυπρακτορικά συστήματα για να συντονίσουν την κίνησή τους χωρίς συγκρούσεις."
  },
  {
    "question": "Ποιο είναι το κύριο πλεονέκτημα της Ιεραρχικής Ενισχυτικής Μάθησης;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η μείωση της μνήμης RAM.",
      "B": "Η εξάλειψη των αλγορίθμων.",
      "C": "Η διαχείριση εργασιών με μακροχρόνιο ορίζοντα.",
      "D": "Η αύξηση της θερμοκρασίας του επεξεργαστή."
    },
    "explanation": "Η ιεραρχική δομή επιτρέπει στον πράκτορα να σχεδιάζει σε υψηλότερο επίπεδο αφαίρεσης για μακροπρόθεσμους στόχους."
  },
  {
    "question": "Τι είναι η «Ποινή» (Penalty) στην Ενισχυτική Μάθηση;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Μια αρνητική ανταμοιβή για ανεπιθύμητη ενέργεια.",
      "B": "Η διαγραφή του λογισμικού.",
      "C": "Η αύξηση της ταχύτητας του ρομπότ.",
      "D": "Ένα μήνυμα λάθους στην οθόνη."
    },
    "explanation": "Η ποινή λειτουργεί ως αρνητική ενίσχυση για να αποτρέψει τον πράκτορα από το να επαναλάβει λανθασμένες ενέργειες."
  },
  {
    "question": "Πώς ονομάζεται η διαδικασία μάθησης χωρίς ανθρώπινη παρέμβαση στη μελέτη περίπτωσης;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 245",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Χειροκίνητη ρύθμιση.",
      "B": "Επίβλεψη από ειδικούς.",
      "C": "Στατιστική δειγματοληψία.",
      "D": "Αυτόνομη μάθηση."
    },
    "explanation": "Το ζητούμενο ήταν ένα σύστημα ικανό να προσαρμόζεται χωρίς ανθρώπινη παρέμβαση."
  },
  {
    "question": "Τι εξασφαλίζει η πολιτική ασφαλείας (safety policy) στην ΕΜ;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Ότι το σύστημα θα είναι φθηνό.",
      "B": "Ότι ο πράκτορας δεν θα προβεί σε επικίνδυνες ενέργειες κατά την εξερεύνηση.",
      "C": "Ότι τα δεδομένα θα είναι κρυπτογραφημένα.",
      "D": "Ότι το σύστημα θα λειτουργεί μόνο τη μέρα."
    },
    "explanation": "Είναι κρίσιμο να υπάρχουν όρια ασφαλείας ώστε η διαδικασία μάθησης να μην προκαλέσει ζημιά στον πραγματικό κόσμο."
  },
  {
    "question": "Ποια είναι η βασική διαφορά μεταξύ DRL και απλής RL;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η απλή RL είναι πιο γρήγορη.",
      "B": "Η DRL δεν χρησιμοποιεί ανταμοιβές.",
      "C": "Η DRL χρησιμοποιεί βαθιά νευρωνικά δίκτυα για προσέγγιση συναρτήσεων.",
      "D": "Η απλή RL χρησιμοποιείται μόνο σε ρομπότ."
    },
    "explanation": "Η DRL επεκτείνει την RL χρησιμοποιώντας Deep Neural Networks για να χειριστεί πολύπλοκα εισερχόμενα δεδομένα."
  },
  {
    "question": "Ποιο στοιχείο καθορίζει πόσο «καλή» είναι μια κατάσταση για τον πράκτορα;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 236",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η Συνάρτηση Αξίας (Value Function).",
      "B": "Η ταχύτητα του επεξεργαστή.",
      "C": "Το μέγεθος της μνήμης.",
      "D": "Ο αριθμός των αισθητήρων."
    },
    "explanation": "Η συνάρτηση αξίας ποσοτικοποιεί την αναμενόμενη χρησιμότητα μιας κατάστασης."
  },
  {
    "question": "Τι είναι το «Περιβάλλον» (Environment) στην ΕΜ;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Ο χώρος όπου ζουν οι προγραμματιστές.",
      "B": "Η θερμοκρασία του δωματίου.",
      "C": "Το λειτουργικό σύστημα του υπολογιστή.",
      "D": "Ο κόσμος στον οποίο λειτουργεί και αλληλεπιδρά ο πράκτορας."
    },
    "explanation": "Το περιβάλλον είναι το σύστημα ή ο κόσμος εντός του οποίου κινείται και δρα ο πράκτορας."
  },
  {
    "question": "Πώς βελτιώνεται η απόδοση στη βιομηχανική παραγωγή με ΕΜ;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Με την αύξηση των διαλειμμάτων.",
      "B": "Με την ελαχιστοποίηση σφαλμάτων και τη βελτιστοποίηση ροών.",
      "C": "Με τη μείωση των μισθών.",
      "D": "Με την αγορά φθηνότερων υλικών."
    },
    "explanation": "Η ΕΜ βοηθά στη μείωση σφαλμάτων και στην προσαρμογή των ταχυτήτων παραγωγής για βέλτιστη απόδοση."
  },
  {
    "question": "Ποια είναι η λειτουργία των αισθητήρων στα αυτόνομα οχήματα που χρησιμοποιούν ΕΜ;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Να καταγράφουν τη μουσική.",
      "B": "Να μετρούν την πίεση των ελαστικών.",
      "C": "Να παρέχουν δεδομένα για την αντίληψη του περιβάλλοντος.",
      "D": "Να ελέγχουν τον κλιματισμό."
    },
    "explanation": "Οι αισθητήρες τροφοδοτούν το σύστημα με δεδομένα ώστε ο πράκτορας να αντιλαμβάνεται το δρόμο και τα εμπόδια."
  },
  {
    "question": "Γιατί είναι δύσκολη η εκπαίδευση σε δυναμικά περιβάλλοντα;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Επειδή οι συνθήκες αλλάζουν συνεχώς και απρόβλεπτα.",
      "B": "Επειδή δεν υπάρχουν υπολογιστές.",
      "C": "Επειδή οι αλγόριθμοι είναι πολύ αργοί.",
      "D": "Επειδή τα δεδομένα είναι πολύ μικρά."
    },
    "explanation": "Σε δυναμικά περιβάλλοντα, αυτό που ίσχυε χθες μπορεί να μην ισχύει σήμερα, απαιτώντας συνεχή προσαρμογή."
  },
  {
    "question": "Ποιο σύστημα ενσωματώθηκε στην πλατφόρμα της εταιρείας στη μελέτη περίπτωσης;",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 246",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Customer Relationship Management (CRM).",
      "B": "Enterprise Resource Planning (ERP).",
      "C": "Content Management System (CMS).",
      "D": "Microgrid Management System."
    },
    "explanation": "Το σύστημα βαθιάς ενισχυτικής μάθησης ενσωματώθηκε στο Microgrid Management System της εταιρείας."
  },
  {
    "question": "Τι επιτυγχάνει η «Συνεργασία» (Cooperation) στα πολυπρακτορικά συστήματα;",
    "answer": "B",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 239",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Τη μείωση της συνολικής απόδοσης.",
      "B": "Την επίτευξη κοινών στόχων που δεν μπορεί να πετύχει ένας μόνος πράκτορας.",
      "C": "Την αύξηση του ανταγωνισμού.",
      "D": "Την αποτυχία του συστήματος."
    },
    "explanation": "Η συνεργασία επιτρέπει την επίλυση προβλημάτων που απαιτούν συντονισμό πολλών μονάδων."
  },
  {
    "question": "Ποια είναι η έννοια της «Ανταμοιβής» (Reward);",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Το σήμα που δείχνει την επιτυχία ή αποτυχία μιας ενέργειας.",
      "B": "Το χρηματικό ποσό που πληρώνεται ο προγραμματιστής.",
      "C": "Η ποσότητα ρεύματος που καταναλώνει το ρομπότ.",
      "D": "Η ταχύτητα σύνδεσης στο διαδίκτυο."
    },
    "explanation": "Η ανταμοιβή είναι το σήμα ανατροφοδότησης που καθοδηγεί τη μάθηση του πράκτορα."
  },
  {
    "question": "Τι προσπαθεί να μεγιστοποιήσει ο πράκτορας στην ΕΜ;",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 234",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Τον αριθμό των λαθών.",
      "B": "Τον χρόνο εκτέλεσης.",
      "C": "Τη συνολική αθροιστική ανταμοιβή.",
      "D": "Τον όγκο των δεδομένων."
    },
    "explanation": "Ο βασικός στόχος του πράκτορα είναι να βρει μια στρατηγική που μεγιστοποιεί το άθροισμα των ανταμοιβών στο χρόνο."
  },
  {
    "question": "Ποια εφαρμογή ΕΜ σχετίζεται με την «Έξυπνη Πόλη»;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Η αυτόματη συγγραφή βιβλίων.",
      "B": "Η δημιουργία μουσικής.",
      "C": "Η ανάλυση ιστορικών κειμένων.",
      "D": "Η διαχείριση της κυκλοφορίας και των φαναριών."
    },
    "explanation": "Η διαχείριση κυκλοφορίας είναι μια κλασική εφαρμογή για τη βελτίωση της ζωής στις έξυπνες πόλεις."
  },
  {
    "question": "Τι είναι το «Actor» στο μοντέλο Actor-Critic;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Το τμήμα που αξιολογεί την κατάσταση.",
      "B": "Το τμήμα που επιλέγει την ενέργεια προς εκτέλεση.",
      "C": "Το τμήμα που αποθηκεύει τα δεδομένα.",
      "D": "Το τμήμα που συνδέεται στο διαδίκτυο."
    },
    "explanation": "Ο Actor είναι υπεύθυνος για τη λήψη αποφάσεων και την επιλογή ενεργειών βάσει της πολιτικής."
  },
  {
    "question": "Ποια πρόκληση σχετίζεται με την «Κλίμακα» (Scalability);",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Η διαχείριση τεράστιων χώρων καταστάσεων και ενεργειών.",
      "B": "Η αγορά μεγαλύτερων οθονών.",
      "C": "Η αύξηση του μισθού των υπαλλήλων.",
      "D": "Η μεταφορά του εξοπλισμού σε μεγαλύτερο κτίριο."
    },
    "explanation": "Η επεκτασιμότητα αφορά τη δυσκολία εφαρμογής αλγορίθμων σε προβλήματα με πολύ μεγάλους χώρους αναζήτησης."
  },
  {
    "question": "Τι προσφέρει η «Πολιτική» (Policy) στον πράκτορα;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 236",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Του δίνει φαγητό.",
      "B": "Του δίνει ρεύμα.",
      "C": "Τον καθοδηγεί στο τι να κάνει σε κάθε κατάσταση.",
      "D": "Τον προστατεύει από ιούς."
    },
    "explanation": "Η πολιτική είναι ο χάρτης συμπεριφοράς του πράκτορα, λέγοντάς του ποια ενέργεια να διαλέξει."
  },
  {
    "question": "Ποια τεχνική βοηθά στην εκμάθηση σε περιβάλλοντα με σπάνιες ανταμοιβές;",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Η μείωση της μνήμης.",
      "B": "Η αύξηση της θερμοκρασίας.",
      "C": "Η διαγραφή των παλιών δεδομένων.",
      "D": "Η διαμόρφωση ανταμοιβών (Reward Shaping)."
    },
    "explanation": "Το Reward Shaping προσθέτει ενδιάμεσες ανταμοιβές για να καθοδηγήσει τον πράκτορα όταν ο τελικός στόχος είναι μακρινός."
  },
  {
    "question": "Ποιο είναι το αποτέλεσμα της εφαρμογής DRL στα μικροδίκτυα;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 247",
      "paragraph": "4η παράγραφος"
    },
    "choices": {
      "A": "Σημαντικά οφέλη στην αποδοτικότητα και βιωσιμότητα.",
      "B": "Καμία αλλαγή στην απόδοση.",
      "C": "Αύξηση του κόστους λειτουργίας.",
      "D": "Συχνές διακοπές ρεύματος."
    },
    "explanation": "Η μελέτη καταλήγει ότι η εφαρμογή έφερε σημαντικά οφέλη στη διαχείριση των μικροδικτύων."
  },
  {
    "question": "Τι είναι τα «Cobots»;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 265",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Ρομπότ που μάχονται μεταξύ τους.",
      "B": "Συνεργατικά ρομπότ που δουλεύουν με ανθρώπους.",
      "C": "Ρομπότ που φτιάχνουν καφέ.",
      "D": "Ρομπότ που παίζουν σκάκι."
    },
    "explanation": "Αν και η σελίδα 265 είναι εκτός της αρχικής ερώτησης, ο όρος εμφανίζεται και στη ρομποτική (παρ. 9.4.1), αλλά ας μείνουμε στο Κεφ 8. Στο 8.6.3 αναφέρονται προσαρμοστικά συστήματα, αλλά η λέξη cobot είναι στο Κεφ 9. Θα αλλάξω την ερώτηση για να μείνω αυστηρά στο Κεφ 8."
  },
  {
    "question": "Ποια είναι η βασική αρχή της «Δοκιμής και Σφάλματος» (Trial and Error);",
    "answer": "C",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 234",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Να διαβάζεις το εγχειρίδιο πριν κάνεις οτιδήποτε.",
      "B": "Να ρωτάς πάντα έναν ειδικό.",
      "C": "Να μαθαίνεις δοκιμάζοντας ενέργειες και βλέποντας το αποτέλεσμα.",
      "D": "Να μην κάνεις τίποτα για να μην κάνεις λάθος."
    },
    "explanation": "Είναι η διαδικασία όπου ο πράκτορας εξερευνά το περιβάλλον κάνοντας ενέργειες για να δει τι αποτέλεσμα έχουν."
  },
  {
    "question": "Τι σημαίνει ο όρος «Ενισχυτική» στην ΕΜ;",
    "answer": "D",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 234",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Ότι χρησιμοποιούμε ενισχυτές ήχου.",
      "B": "Ότι το σύστημα είναι πολύ δυνατό.",
      "C": "Ότι προσθέτουμε περισσότερη μνήμη.",
      "D": "Ότι η συμπεριφορά ενισχύεται (ή αποθαρρύνεται) από τις συνέπειες."
    },
    "explanation": "Ο όρος προέρχεται από την ψυχολογία συμπεριφοράς, όπου μια συμπεριφορά ενισχύεται όταν ακολουθείται από θετικό αποτέλεσμα."
  },
  {
    "question": "Ποια είναι η σχέση της ΕΜ με τη Μηχανική Μάθηση;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 233",
      "paragraph": "Τίτλος/Εισαγωγή"
    },
    "choices": {
      "A": "Είναι ένας από τους τρεις βασικούς πυλώνες της.",
      "B": "Είναι εντελώς άσχετη.",
      "C": "Είναι ανταγωνιστική τεχνολογία.",
      "D": "Είναι παλαιότερη τεχνολογία που καταργήθηκε."
    },
    "explanation": "Η ΕΜ θεωρείται ο τρίτος βασικός τύπος μηχανικής μάθησης, δίπλα στην Επιβλεπόμενη και Μη Επιβλεπόμενη."
  },
  {
    "question": "Τι μπορεί να συμβεί αν η «Εξερεύνηση» είναι υπερβολική;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 241",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Το σύστημα θα γίνει τέλειο αμέσως.",
      "B": "Ο πράκτορας δεν θα αξιοποιήσει ποτέ τη γνώση που απέκτησε.",
      "C": "Το σύστημα θα κλείσει.",
      "D": "Οι ανταμοιβές θα διπλασιαστούν."
    },
    "explanation": "Αν ο πράκτορας εξερευνά συνεχώς, δεν εκμεταλλεύεται τις καλές στρατηγικές που έχει ήδη βρει για να μαζέψει πόντους."
  },
  {
    "question": "Τι μπορεί να συμβεί αν η «Εκμετάλλευση» είναι υπερβολική;",
    "answer": "C",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 241",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Ο πράκτορας θα μάθει τα πάντα.",
      "B": "Το σύστημα θα καταρρεύσει.",
      "C": "Ο πράκτορας μπορεί να παγιδευτεί σε τοπικά βέλτιστα και να χάσει καλύτερες λύσεις.",
      "D": "Οι ανταμοιβές θα μηδενιστούν."
    },
    "explanation": "Χωρίς εξερεύνηση, ο πράκτορας δεν θα ανακαλύψει ποτέ πιθανές καλύτερες στρατηγικές που δεν έχει δοκιμάσει ακόμα."
  },
  {
    "question": "Ποιο είναι το βασικό χαρακτηριστικό των «Προσαρμοστικών Συστημάτων Παραγωγής»;",
    "answer": "D",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Είναι στατικά και αμετάβλητα.",
      "B": "Απαιτούν χειροκίνητη ρύθμιση κάθε ώρα.",
      "C": "Λειτουργούν μόνο με ηλιακή ενέργεια.",
      "D": "Προσαρμόζουν τη λειτουργία τους ανάλογα με τις συνθήκες."
    },
    "explanation": "Η ικανότητα προσαρμογής σε πραγματικό χρόνο (π.χ. ταχύτητα, ροή) είναι το κλειδί για την αποδοτικότητα."
  },
  {
    "question": "Σε ποιο επίπεδο λειτουργεί η Ιεραρχική Ενισχυτική Μάθηση;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Σε πολλαπλά επίπεδα αφαίρεσης (ιεραρχία).",
      "B": "Μόνο στο χαμηλότερο επίπεδο εντολών.",
      "C": "Μόνο στο επίπεδο του υλικού (hardware).",
      "D": "Σε κανένα επίπεδο."
    },
    "explanation": "Η HRL δομεί το πρόβλημα σε ιεραρχία, από υψηλού επιπέδου στρατηγικές σε χαμηλού επιπέδου ενέργειες."
  },
  {
    "question": "Τι είναι τα «Δυναμικά Περιβάλλοντα» (Dynamic Environments);",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Περιβάλλοντα που δεν αλλάζουν ποτέ.",
      "B": "Περιβάλλοντα που αλλάζουν με την πάροδο του χρόνου.",
      "C": "Περιβάλλοντα χωρίς βαρύτητα.",
      "D": "Περιβάλλοντα με δυνατή μουσική."
    },
    "explanation": "Δυναμικά είναι τα περιβάλλοντα όπου οι κανόνες ή η κατάσταση μεταβάλλονται αυτόνομα ή αντιδραστικά."
  },
  {
    "question": "Ποια τεχνολογία επιτρέπει την «Ανθεκτική Εξερεύνηση»;",
    "answer": "C",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 246",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Τα απλά IF-THEN statements.",
      "B": "Οι βρόχοι FOR loops.",
      "C": "Robust Exploration Strategies.",
      "D": "Οι πίνακες Excel."
    },
    "explanation": "Στη μελέτη περίπτωσης αναφέρεται η χρήση Robust Exploration Strategies για ασφαλή δοκιμή νέων ενεργειών."
  },
  {
    "question": "Τι κάνει ο «Critic» στο Actor-Critic;",
    "answer": "A",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "2η παράγραφος"
    },
    "choices": {
      "A": "Αξιολογεί την ενέργεια που επέλεξε ο Actor.",
      "B": "Εκτελεί την ενέργεια.",
      "C": "Διαγράφει την ενέργεια.",
      "D": "Αγνοεί την ενέργεια."
    },
    "explanation": "Ο Critic παρέχει ανατροφοδότηση (αξιολόγηση) για το πόσο καλή ήταν η επιλογή του Actor."
  },
  {
    "question": "Ποιος είναι ο στόχος της «Βελτιστοποίησης Βαθμίδας Πολιτικής» (Policy Gradient);",
    "answer": "D",
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Να βρει την ελάχιστη ανταμοιβή.",
      "B": "Να μηδενίσει τις παραμέτρου.",
      "C": "Να αντιγράψει μια άλλη πολιτική.",
      "D": "Να βελτιστοποιήσει απευθείας την πολιτική προς τη μέγιστη ανταμοιβή."
    },
    "explanation": "Αντί να υπολογίζει αξίες καταστάσεων, η μέθοδος αυτή προσαρμόζει απευθείας την πολιτική."
  },
  {
    "question": "Ποιο παράδειγμα εφαρμογής ΕΜ αναφέρεται για την ενέργεια;",
    "answer": "A",
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "3η παράγραφος"
    },
    "choices": {
      "A": "Δυναμική Διαχείριση Ενεργειακών Δικτύων.",
      "B": "Κατασκευή ηλιακών πάνελ.",
      "C": "Εξόρυξη άνθρακα.",
      "D": "Πώληση μπαταριών."
    },
    "explanation": "Η ΕΜ χρησιμοποιείται για τη βελτιστοποίηση της ροής και διανομής ενέργειας."
  },
  {
    "question": "Τι προσφέρει η DRL στα αυτόνομα οχήματα;",
    "answer": "B",
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "1η παράγραφος"
    },
    "choices": {
      "A": "Καλύτερο ηχοσύστημα.",
      "B": "Ικανότητα λήψης αποφάσεων σε απρόβλεπτα περιβάλλοντα.",
      "C": "Φθηνότερα καύσιμα.",
      "D": "Πιο άνετα καθίσματα."
    },
    "explanation": "Η DRL επιτρέπει στο όχημα να επεξεργάζεται δεδομένα αισθητήρων και να αποφασίζει πώς να κινηθεί με ασφάλεια."
  }
]
